#+TITLE: 20-Hour Agentic AI Study Roadmap
#+AUTHOR: AI Learning Path
#+DATE: 2024

* Overview
The essential skills needed to build and deploy AI agents effectively.
*Focus:* 20% of skills that drive 80% of results

* Session 1: Python Fundamentals & API Basics (2 hours)
*Focus:* Core programming skills for AI agents

** Hour 1: Python Essentials

#+BEGIN_SRC python
# Essential Python for AI Agents
import requests
import json
import asyncio
from typing import Dict, List, Optional

# Basic HTTP requests
def make_api_call(url: str, params: Dict = None) -> Dict:
    """Basic API call function"""
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        print(f"API call failed: {e}")
        return {}

# File operations for agents
def read_config(file_path: str) -> Dict:
    """Read configuration from JSON file"""
    with open(file_path, 'r') as f:
        return json.load(f)

def log_agent_action(action: str, result: str):
    """Log agent actions"""
    with open('agent_log.txt', 'a') as f:
        f.write(f"{action}: {result}\n")
#+END_SRC

** Hour 2: Async Programming & Error Handling

#+BEGIN_SRC python
# Async programming for concurrent agent operations
import asyncio
import aiohttp

async def async_api_call(session, url: str) -> Dict:
    """Async API call for better performance"""
    try:
        async with session.get(url) as response:
            return await response.json()
    except Exception as e:
        return {"error": str(e)}

async def parallel_agent_tasks():
    """Run multiple agent tasks concurrently"""
    async with aiohttp.ClientSession() as session:
        tasks = [
            async_api_call(session, "https://api.example1.com"),
            async_api_call(session, "https://api.example2.com")
        ]
        results = await asyncio.gather(*tasks)
        return results

# Error handling patterns
class AgentError(Exception):
    """Custom exception for agent errors"""
    pass

def robust_agent_function(data):
    """Agent function with proper error handling"""
    try:
        # Process data
        if not data:
            raise AgentError("No data provided")
        return {"status": "success", "result": data}
    except Exception as e:
        return {"status": "error", "message": str(e)}
#+END_SRC

** 15-min Review Questions:
1. How do you handle API failures in agent code?
2. When should you use async programming in agents?
3. What are the key Python patterns for agent development?

* Session 2: LLM APIs & Prompt Engineering (2 hours)
*Focus:* Working with language models effectively

** Hour 1: OpenAI API Integration

#+BEGIN_SRC python
import openai
from typing import List, Dict

class LLMAgent:
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
    
    def chat_completion(self, messages: List[Dict], model: str = "gpt-4") -> str:
        """Basic chat completion"""
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error: {str(e)}"
    
    def structured_prompt(self, task: str, context: str) -> str:
        """Create structured prompt for consistent results"""
        messages = [
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": f"Task: {task}\nContext: {context}"}
        ]
        return self.chat_completion(messages)

# Example usage
agent = LLMAgent("your-api-key")
result = agent.structured_prompt(
    task="Summarize the key points",
    context="Long document text here..."
)
#+END_SRC

** Hour 2: Advanced Prompting Techniques

#+BEGIN_SRC python
class AdvancedPrompts:
    @staticmethod
    def chain_of_thought_prompt(problem: str) -> str:
        """Chain of thought prompting for complex reasoning"""
        return f"""
Let's think about this step by step:

Problem: {problem}

Step 1: Identify the key components
Step 2: Analyze relationships
Step 3: Apply logical reasoning
Step 4: Draw conclusions

Please work through each step carefully.
"""
    
    @staticmethod
    def role_based_prompt(role: str, task: str, constraints: str = "") -> List[Dict]:
        """Create role-based prompts"""
        system_message = f"You are a {role}. {constraints}"
        return [
            {"role": "system", "content": system_message},
            {"role": "user", "content": task}
        ]
    
    @staticmethod
    def few_shot_prompt(examples: List[Dict], new_input: str) -> str:
        """Few-shot learning prompt"""
        prompt = "Here are some examples:\n\n"
        for i, example in enumerate(examples, 1):
            prompt += f"Example {i}:\nInput: {example['input']}\nOutput: {example['output']}\n\n"
        prompt += f"Now, given this input: {new_input}\nOutput:"
        return prompt

# Example usage
examples = [
    {"input": "Hello", "output": "Greeting detected"},
    {"input": "Goodbye", "output": "Farewell detected"}
]
prompt = AdvancedPrompts.few_shot_prompt(examples, "See you later")
#+END_SRC

** 15-min Review Questions:
1. What makes a good system prompt?
2. How does chain-of-thought improve reasoning?
3. When should you use few-shot vs zero-shot prompting?

* Session 3: Agent Architecture & Decision Making (2 hours)
*Focus:* Building intelligent agent behavior

** Hour 1: Basic Agent Architecture

#+BEGIN_SRC python
from abc import ABC, abstractmethod
from enum import Enum
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

class AgentState(Enum):
    IDLE = "idle"
    THINKING = "thinking"
    ACTING = "acting"
    COMPLETE = "complete"
    ERROR = "error"

@dataclass
class AgentAction:
    name: str
    parameters: Dict[str, Any]
    timestamp: str

class Agent(ABC):
    def __init__(self, name: str):
        self.name = name
        self.state = AgentState.IDLE
        self.memory = []
        self.actions_taken = []
    
    @abstractmethod
    def perceive(self, environment: Dict) -> Dict:
        """Perceive the current environment"""
        pass
    
    @abstractmethod
    def decide(self, perception: Dict) -> AgentAction:
        """Decide what action to take"""
        pass
    
    @abstractmethod
    def act(self, action: AgentAction) -> Dict:
        """Execute the decided action"""
        pass
    
    def run_cycle(self, environment: Dict) -> Dict:
        """Main agent loop: perceive -> decide -> act"""
        try:
            self.state = AgentState.THINKING
            perception = self.perceive(environment)
            
            action = self.decide(perception)
            
            self.state = AgentState.ACTING
            result = self.act(action)
            
            self.actions_taken.append(action)
            self.state = AgentState.COMPLETE
            
            return result
        except Exception as e:
            self.state = AgentState.ERROR
            return {"error": str(e)}

class SimpleTaskAgent(Agent):
    def __init__(self, name: str, llm_client):
        super().__init__(name)
        self.llm = llm_client
    
    def perceive(self, environment: Dict) -> Dict:
        """Extract relevant information from environment"""
        return {
            "task": environment.get("task", ""),
            "available_tools": environment.get("tools", []),
            "context": environment.get("context", "")
        }
    
    def decide(self, perception: Dict) -> AgentAction:
        """Use LLM to decide on action"""
        prompt = f"""
        Given this situation:
        Task: {perception['task']}
        Available tools: {perception['available_tools']}
        Context: {perception['context']}
        
        What action should I take? Respond with JSON:
        {{"action": "tool_name", "parameters": {{"key": "value"}}}}
        """
        
        response = self.llm.chat_completion([
            {"role": "user", "content": prompt}
        ])
        
        # Parse LLM response (simplified)
        import json
        try:
            action_data = json.loads(response)
            return AgentAction(
                name=action_data["action"],
                parameters=action_data["parameters"],
                timestamp=str(datetime.now())
            )
        except:
            return AgentAction("error", {}, str(datetime.now()))
#+END_SRC

** Hour 2: ReAct Pattern Implementation

#+BEGIN_SRC python
class ReActAgent(Agent):
    """Reasoning and Acting agent following ReAct pattern"""
    
    def __init__(self, name: str, llm_client, tools: Dict):
        super().__init__(name)
        self.llm = llm_client
        self.tools = tools
        self.thought_history = []
    
    def think(self, observation: str) -> str:
        """Generate reasoning about current situation"""
        prompt = f"""
        You are solving a task step by step.
        
        Previous thoughts: {self.thought_history[-3:] if self.thought_history else "None"}
        Current observation: {observation}
        
        Think: What should I reason about this observation?
        """
        
        thought = self.llm.chat_completion([{"role": "user", "content": prompt}])
        self.thought_history.append(thought)
        return thought
    
    def plan_action(self, thought: str) -> AgentAction:
        """Plan next action based on reasoning"""
        available_tools = list(self.tools.keys())
        
        prompt = f"""
        Based on this reasoning: {thought}
        Available tools: {available_tools}
        
        Act: What specific action should I take?
        Respond with: Action[tool_name(parameter=value)]
        """
        
        action_text = self.llm.chat_completion([{"role": "user", "content": prompt}])
        
        # Parse action (simplified)
        if "Action[" in action_text:
            # Extract tool and parameters
            tool_name = "search"  # Simplified parsing
            parameters = {"query": "example"}
            return AgentAction(tool_name, parameters, str(datetime.now()))
        
        return AgentAction("think", {}, str(datetime.now()))
    
    def execute_react_cycle(self, initial_task: str, max_steps: int = 5):
        """Execute ReAct reasoning cycle"""
        observation = f"Task: {initial_task}"
        
        for step in range(max_steps):
            # Think
            thought = self.think(observation)
            print(f"Think: {thought}")
            
            # Act
            action = self.plan_action(thought)
            print(f"Act: {action.name}({action.parameters})")
            
            # Execute action and get observation
            if action.name in self.tools:
                observation = self.tools[action.name](action.parameters)
            else:
                observation = "Action not recognized"
            
            print(f"Observation: {observation}")
            
            # Check if task is complete
            if "FINAL ANSWER" in observation.upper():
                break
        
        return self.thought_history, self.actions_taken

# Example tools
def search_tool(params):
    return f"Search results for: {params.get('query', 'N/A')}"

def calculator_tool(params):
    try:
        return str(eval(params.get('expression', '0')))
    except:
        return "Calculation error"

# Usage
tools = {
    "search": search_tool,
    "calculator": calculator_tool
}

agent = ReActAgent("ReAct Agent", llm_client, tools)
agent.execute_react_cycle("What is 25 * 4 + 10?")
#+END_SRC

** 15-min Review Questions:
1. What are the key components of agent architecture?
2. How does the ReAct pattern improve agent reasoning?
3. When should you use different agent patterns?

* Session 4: Tool Integration & Function Calling (2 hours)
*Focus:* Connecting agents to external tools and APIs

** Hour 1: OpenAI Function Calling

#+BEGIN_SRC python
import json
from typing import List, Dict, Callable

class FunctionCallingAgent:
    def __init__(self, openai_client):
        self.client = openai_client
        self.available_functions = {}
    
    def register_function(self, name: str, func: Callable, description: str, parameters: Dict):
        """Register a function that the agent can call"""
        self.available_functions[name] = {
            "function": func,
            "description": description,
            "parameters": parameters
        }
    
    def get_function_definitions(self) -> List[Dict]:
        """Get OpenAI function definitions"""
        functions = []
        for name, info in self.available_functions.items():
            functions.append({
                "name": name,
                "description": info["description"],
                "parameters": info["parameters"]
            })
        return functions
    
    def execute_with_tools(self, user_message: str) -> str:
        """Execute agent with function calling capability"""
        messages = [{"role": "user", "content": user_message}]
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            functions=self.get_function_definitions(),
            function_call="auto"
        )
        
        message = response.choices[0].message
        
        if message.function_call:
            # Execute the function
            function_name = message.function_call.name
            function_args = json.loads(message.function_call.arguments)
            
            if function_name in self.available_functions:
                function_result = self.available_functions[function_name]["function"](**function_args)
                
                # Add function result to conversation
                messages.append({
                    "role": "function",
                    "name": function_name,
                    "content": str(function_result)
                })
                
                # Get final response
                final_response = self.client.chat.completions.create(
                    model="gpt-4",
                    messages=messages
                )
                
                return final_response.choices[0].message.content
        
        return message.content

# Example functions to register
def get_weather(location: str) -> str:
    """Mock weather function"""
    return f"The weather in {location} is sunny, 72°F"

def calculate(expression: str) -> float:
    """Safe calculator function"""
    try:
        # In production, use a safe evaluator
        result = eval(expression)
        return result
    except:
        return "Calculation error"

def search_web(query: str) -> str:
    """Mock web search function"""
    return f"Search results for '{query}': Found 10 relevant articles"

# Register functions
agent = FunctionCallingAgent(openai_client)

agent.register_function(
    name="get_weather",
    func=get_weather,
    description="Get current weather for a location",
    parameters={
        "type": "object",
        "properties": {
            "location": {"type": "string", "description": "City name"}
        },
        "required": ["location"]
    }
)

agent.register_function(
    name="calculate",
    func=calculate,
    description="Perform mathematical calculations",
    parameters={
        "type": "object",
        "properties": {
            "expression": {"type": "string", "description": "Mathematical expression"}
        },
        "required": ["expression"]
    }
)
#+END_SRC

** Hour 2: Custom Tool System

#+BEGIN_SRC python
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
import inspect

class Tool(ABC):
    """Base class for agent tools"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        pass
    
    @property
    @abstractmethod
    def description(self) -> str:
        pass
    
    @abstractmethod
    def execute(self, **kwargs) -> Any:
        pass
    
    def get_parameters(self) -> Dict:
        """Extract parameters from execute method signature"""
        sig = inspect.signature(self.execute)
        parameters = {
            "type": "object",
            "properties": {},
            "required": []
        }
        
        for param_name, param in sig.parameters.items():
            if param_name != 'self':
                param_info = {"type": "string"}  # Default type
                if param.annotation != inspect.Parameter.empty:
                    if param.annotation == int:
                        param_info["type"] = "integer"
                    elif param.annotation == float:
                        param_info["type"] = "number"
                    elif param.annotation == bool:
                        param_info["type"] = "boolean"
                
                parameters["properties"][param_name] = param_info
                
                if param.default == inspect.Parameter.empty:
                    parameters["required"].append(param_name)
        
        return parameters

class WebSearchTool(Tool):
    @property
    def name(self) -> str:
        return "web_search"
    
    @property
    def description(self) -> str:
        return "Search the web for information"
    
    def execute(self, query: str, max_results: int = 5) -> str:
        # Mock implementation
        return f"Found {max_results} results for '{query}'"

class FileReaderTool(Tool):
    @property
    def name(self) -> str:
        return "read_file"
    
    @property
    def description(self) -> str:
        return "Read contents of a file"
    
    def execute(self, file_path: str) -> str:
        try:
            with open(file_path, 'r') as f:
                return f.read()
        except Exception as e:
            return f"Error reading file: {str(e)}"

class EmailTool(Tool):
    @property
    def name(self) -> str:
        return "send_email"
    
    @property
    def description(self) -> str:
        return "Send an email"
    
    def execute(self, to: str, subject: str, body: str) -> str:
        # Mock implementation
        return f"Email sent to {to} with subject '{subject}'"

class ToolManager:
    def __init__(self):
        self.tools: Dict[str, Tool] = {}
    
    def register_tool(self, tool: Tool):
        """Register a tool"""
        self.tools[tool.name] = tool
    
    def get_tool_definitions(self) -> List[Dict]:
        """Get all tool definitions for LLM"""
        definitions = []
        for tool in self.tools.values():
            definitions.append({
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.get_parameters()
            })
        return definitions
    
    def execute_tool(self, tool_name: str, **kwargs) -> Any:
        """Execute a tool by name"""
        if tool_name in self.tools:
            return self.tools[tool_name].execute(**kwargs)
        else:
            raise ValueError(f"Tool {tool_name} not found")

# Usage example
tool_manager = ToolManager()
tool_manager.register_tool(WebSearchTool())
tool_manager.register_tool(FileReaderTool())
tool_manager.register_tool(EmailTool())

# Integration with agent
class ToolEnabledAgent:
    def __init__(self, llm_client, tool_manager: ToolManager):
        self.llm = llm_client
        self.tool_manager = tool_manager
    
    def process_request(self, user_input: str) -> str:
        """Process user request with tool access"""
        tools = self.tool_manager.get_tool_definitions()
        
        messages = [
            {"role": "system", "content": "You are a helpful assistant with access to tools."},
            {"role": "user", "content": user_input}
        ]
        
        response = self.llm.chat.completions.create(
            model="gpt-4",
            messages=messages,
            functions=tools,
            function_call="auto"
        )
        
        message = response.choices[0].message
        
        if message.function_call:
            tool_name = message.function_call.name
            tool_args = json.loads(message.function_call.arguments)
            
            try:
                result = self.tool_manager.execute_tool(tool_name, **tool_args)
                return f"Tool executed: {result}"
            except Exception as e:
                return f"Tool execution failed: {str(e)}"
        
        return message.content
#+END_SRC

** 15-min Review Questions:
1. How does function calling improve agent capabilities?
2. What are the best practices for tool parameter definition?
3. How do you handle tool execution errors gracefully?

* Session 5: LangChain Framework Fundamentals (2 hours)
*Focus:* Using LangChain for rapid agent development

** Hour 1: LangChain Basics & Chains

#+BEGIN_SRC python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory

# Basic LangChain setup
class LangChainAgent:
    def __init__(self, openai_api_key: str):
        self.llm = OpenAI(openai_api_key=openai_api_key, temperature=0.7)
        self.memory = ConversationBufferMemory()
    
    def create_simple_chain(self):
        """Create a simple LLM chain"""
        template = """
        You are a helpful assistant. Please answer the following question:
        Question: {question}
        Answer:"""
        
        prompt = PromptTemplate(
            input_variables=["question"],
            template=template
        )
        
        return LLMChain(llm=self.llm, prompt=prompt)
    
    def create_sequential_chain(self):
        """Create a sequential chain for multi-step processing"""
        # First chain: Generate summary
        summary_template = """
        Summarize the following text in one sentence:
        Text: {text}
        Summary:"""
        
        summary_prompt = PromptTemplate(
            input_variables=["text"],
            template=summary_template
        )
        summary_chain = LLMChain(llm=self.llm, prompt=summary_prompt)
        
        # Second chain: Generate action items
        action_template = """
        Based on this summary, generate 3 action items:
        Summary: {summary}
        Action Items:"""
        
        action_prompt = PromptTemplate(
            input_variables=["summary"],
            template=action_template
        )
        action_chain = LLMChain(llm=self.llm, prompt=action_prompt)
        
        # Combine chains
        return SimpleSequentialChain(
            chains=[summary_chain, action_chain],
            verbose=True
        )

# Example usage
agent = LangChainAgent("your-api-key")

# Simple chain
simple_chain = agent.create_simple_chain()
result = simple_chain.run("What is machine learning?")

# Sequential chain
sequential_chain = agent.create_sequential_chain()
long_text = "Long document text here..."
action_items = sequential_chain.run(long_text)
#+END_SRC

** Hour 2: LangChain Agents & Tools

#+BEGIN_SRC python
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from langchain import hub
import requests

class LangChainToolAgent:
    def __init__(self, llm):
        self.llm = llm
        self.tools = self._create_tools()
    
    def _create_tools(self) -> List[Tool]:
        """Create tools for the agent"""
        
        def search_tool(query: str) -> str:
            """Search for information"""
            # Mock search - replace with real API
            return f"Search results for '{query}': Found relevant information about {query}"
        
        def calculator_tool(expression: str) -> str:
            """Calculate mathematical expressions"""
            try:
                result = eval(expression)  # Use safe evaluator in production
                return f"The result is: {result}"
            except Exception as e:
                return f"Calculation error: {str(e)}"
        
        def weather_tool(location: str) -> str:
            """Get weather information"""
            # Mock weather API
            return f"Weather in {location}: Sunny, 72°F"
        
        def file_reader_tool(filename: str) -> str:
            """Read file contents"""
            try:
                with open(filename, 'r') as f:
                    content = f.read()[:500]  # Limit content
                return f"File content: {content}"
            except Exception as e:
                return f"Error reading file: {str(e)}"
        
        return [
            Tool(
                name="Search",
                func=search_tool,
                description="Search for information on the web"
            ),
            Tool(
                name="Calculator",
                func=calculator_tool,
                description="Calculate mathematical expressions"
            ),
            Tool(
                name="Weather",
                func=weather_tool,
                description="Get current weather for a location"
            ),
            Tool(
                name="FileReader",
                func=file_reader_tool,
                description="Read contents of a file"
            )
        ]
    
    def create_react_agent(self):
        """Create a ReAct agent with tools"""
        # Get ReAct prompt from hub
        prompt = hub.pull("hwchase17/react")
        
        # Create agent
        agent = create_react_agent(self.llm, self.tools, prompt)
        
        # Create executor
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=True,
            max_iterations=5
        )
        
        return agent_executor
    
    def run_agent(self, query: str) -> str:
        """Run the agent with a query"""
        agent_executor = self.create_react_agent()
        
        try:
            result = agent_executor.invoke({"input": query})
            return result["output"]
        except Exception as e:
            return f"Agent execution error: {str(e)}"

# Custom prompt template for specialized agent
class CustomAgentPrompt:
    @staticmethod
    def create_research_agent_prompt():
        """Create a prompt for a research agent"""
        template = """
        You are a research assistant agent. Your job is to help users find and analyze information.
        
        You have access to the following tools:
        {tools}
        
        Use the following format:
        
        Question: the input question you must answer
        Thought: you should always think about what to do
        Action: the action to take, should be one of [{tool_names}]
        Action Input: the input to the action
        Observation: the result of the action
        ... (this Thought/Action/Action Input/Observation can repeat N times)
        Thought: I now know the final answer
        Final Answer: the final answer to the original input question
        
        Begin!
        
        Question: {input}
        Thought: {agent_scratchpad}
        """
        
        return PromptTemplate(
            template=template,
            input_variables=["input", "agent_scratchpad", "tools", "tool_names"]
        )

# Memory-enabled agent
class MemoryAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
    
    def create_conversational_agent(self):
        """Create agent with conversation memory"""
        from langchain.agents import ConversationalChatAgent, AgentExecutor
        
        agent = ConversationalChatAgent.from_llm_and_tools(
            llm=self.llm,
            tools=self.tools,
            verbose=True
        )
        
        return AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True
        )
    
    def chat(self, message: str) -> str:
        """Have a conversation with the agent"""
        agent_executor = self.create_conversational_agent()
        return agent_executor.run(input=message)

# Usage examples
llm = OpenAI(temperature=0)
tool_agent = LangChainToolAgent(llm)

# Run simple query
result = tool_agent.run_agent("What's 25 * 4 + 10, and what's the weather like in Paris?")
print(result)

# Memory agent example
memory_agent = MemoryAgent(llm, tool_agent.tools)
response1 = memory_agent.chat("My name is John and I live in New York")
response2 = memory_agent.chat("What's the weather like where I live?")
#+END_SRC

** 15-min Review Questions:
1. What are the advantages of using LangChain over custom implementations?
2. How do chains differ from agents in LangChain?
3. When should you use memory in your agents?

* Session 6: RAG Implementation & Knowledge Management (2 hours)
*Focus:* Building agents that can access and use external knowledge

** Hour 1: Basic RAG Setup

#+BEGIN_SRC python
from langchain.document_loaders import TextLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
import os

class RAGAgent:
    def __init__(self, openai_api_key: str, knowledge_base_path: str):
        self.api_key = openai_api_key
        self.llm = OpenAI(openai_api_key=openai_api_key, temperature=0)
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.knowledge_base_path = knowledge_base_path
        self.vectorstore = None
        self.qa_chain = None
    
    def load_documents(self):
        """Load documents from knowledge base"""
        if os.path.isfile(self.knowledge_base_path):
            loader = TextLoader(self.knowledge_base_path)
        else:
            loader = DirectoryLoader(
                self.knowledge_base_path,
                glob="**/*.txt",
                loader_cls=TextLoader
            )
        
        documents = loader.load()
        return documents
    
    def split_documents(self, documents):
        """Split documents into chunks"""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        
        splits = text_splitter.split_documents(documents)
        return splits
    
    def create_vectorstore(self, documents):
        """Create vector store from documents"""
        splits = self.split_documents(documents)
        
        self.vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=self.embeddings,
            persist_directory="./chroma_db"
        )
        
        return self.vectorstore
    
    def setup_qa_chain(self):
        """Setup QA chain with retrieval"""
        if not self.vectorstore:
            documents = self.load_documents()
            self.create_vectorstore(documents)
        
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 3}
            ),
            return_source_documents=True
        )
    
    def query(self, question: str):
        """Query the knowledge base"""
        if not self.qa_chain:
            self.setup_qa_chain()
        
        result = self.qa_chain({"query": question})
        
        return {
            "answer": result["result"],
            "sources": [doc.page_content[:200] + "..." for doc in result["source_documents"]]
        }

# Advanced RAG with custom retrieval
class AdvancedRAGAgent(RAGAgent):
    def __init__(self, openai_api_key: str, knowledge_base_path: str):
        super().__init__(openai_api_key, knowledge_base_path)
        self.retrieval_strategy = "hybrid"
    
    def create_hybrid_retriever(self):
        """Create hybrid retriever combining semantic and keyword search"""
        from langchain.retrievers import BM25Retriever, EnsembleRetriever
        
        documents = self.load_documents()
        splits = self.split_documents(documents)
        
        # Vector retriever
        vectorstore = self.create_vectorstore(documents)
        vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        
        # Keyword retriever
        bm25_retriever = BM25Retriever.from_documents(splits)
        bm25_retriever.k = 3
        
        # Ensemble retriever
        ensemble_retriever = EnsembleRetriever(
            retrievers=[vector_retriever, bm25_retriever],
            weights=[0.7, 0.3]
        )
        
        return ensemble_retriever
    
    def setup_advanced_qa_chain(self):
        """Setup QA chain with advanced retrieval"""
        retriever = self.create_hybrid_retriever()
        
        from langchain.chains import ConversationalRetrievalChain
        from langchain.memory import ConversationBufferMemory
        
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=retriever,
            memory=memory,
            return_source_documents=True
        )

# Usage example
rag_agent = RAGAgent("your-api-key", "./knowledge_base/")
result = rag_agent.query("What is machine learning?")
print(f"Answer: {result['answer']}")
print(f"Sources: {result['sources']}")
#+END_SRC

** Hour 2: Advanced RAG Techniques

#+BEGIN_SRC python
import chromadb
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

class EnterpriseRAGAgent:
    def __init__(self, openai_api_key: str):
        self.api_key = openai_api_key
        self.llm = OpenAI(openai_api_key=openai_api_key, temperature=0)
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    
    def setup_contextual_compression(self, base_retriever):
        """Setup contextual compression for better retrieval"""
        compressor = LLMChainExtractor.from_llm(self.llm)
        compression_retriever = ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=base_retriever
        )
        return compression_retriever
    
    def setup_multi_query_retriever(self, vectorstore):
        """Setup multi-query retriever for better coverage"""
        base_retriever = vectorstore.as_retriever()
        multi_query_retriever = MultiQueryRetriever.from_llm(
            retriever=base_retriever,
            llm=self.llm
        )
        return multi_query_retriever
    
    def setup_self_query_retriever(self, vectorstore):
        """Setup self-query retriever with metadata filtering"""
        metadata_field_info = [
            AttributeInfo(
                name="source",
                description="The source document",
                type="string"
            ),
            AttributeInfo(
                name="page",
                description="The page number",
                type="integer"
            )
        ]
        
        document_content_description = "Technical documentation"
        
        retriever = SelfQueryRetriever.from_llm(
            self.llm,
            vectorstore,
            document_content_description,
            metadata_field_info,
            verbose=True
        )
        return retriever
    
    def create_rag_chain_with_sources(self, retriever):
        """Create RAG chain that returns sources and confidence"""
        from langchain.chains import RetrievalQAWithSourcesChain
        
        chain = RetrievalQAWithSourcesChain.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True
        )
        return chain

# Custom document processor
class DocumentProcessor:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    def process_pdf(self, pdf_path: str):
        """Process PDF documents"""
        from langchain.document_loaders import PyPDFLoader
        loader = PyPDFLoader(pdf_path)
        pages = loader.load_and_split(self.text_splitter)
        return pages
    
    def process_web_content(self, urls: list):
        """Process web content"""
        from langchain.document_loaders import WebBaseLoader
        loader = WebBaseLoader(urls)
        docs = loader.load()
        splits = self.text_splitter.split_documents(docs)
        return splits
    
    def process_csv_data(self, csv_path: str):
        """Process CSV data"""
        from langchain.document_loaders import CSVLoader
        loader = CSVLoader(csv_path)
        docs = loader.load()
        return docs
    
    def add_metadata(self, documents, metadata: dict):
        """Add metadata to documents"""
        for doc in documents:
            doc.metadata.update(metadata)
        return documents

# Memory-enhanced RAG
class MemoryRAGAgent:
    def __init__(self, openai_api_key: str):
        self.llm = OpenAI(openai_api_key=openai_api_key)
        self.embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        self.conversation_history = []
        self.user_preferences = {}
    
    def personalized_retrieval(self, query: str, vectorstore):
        """Personalized retrieval based on user history"""
        # Enhance query with user context
        context_query = self._add_user_context(query)
        
        retriever = vectorstore.as_retriever(
            search_type="mmr",  # Maximum Marginal Relevance
            search_kwargs={
                "k": 5,
                "fetch_k": 20,
                "lambda_mult": 0.7
            }
        )
        
        docs = retriever.get_relevant_documents(context_query)
        return docs
    
    def _add_user_context(self, query: str) -> str:
        """Add user context to query"""
        if self.conversation_history:
            recent_context = " ".join(self.conversation_history[-3:])
            enhanced_query = f"Context: {recent_context}\nQuery: {query}"
            return enhanced_query
        return query
    
    def update_user_preferences(self, feedback: dict):
        """Update user preferences based on feedback"""
        self.user_preferences.update(feedback)
    
    def log_interaction(self, query: str, response: str):
        """Log user interactions"""
        self.conversation_history.append(f"Q: {query} A: {response}")
        if len(self.conversation_history) > 10:
            self.conversation_history.pop(0)

# Production RAG setup
def setup_production_rag():
    """Setup production-ready RAG system"""
    import logging
    
    # Setup logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # Initialize components
    processor = DocumentProcessor()
    rag_agent = EnterpriseRAGAgent("your-api-key")
    
    # Process documents
    documents = []
    documents.extend(processor.process_pdf("./docs/manual.pdf"))
    documents.extend(processor.process_web_content(["https://docs.example.com"]))
    
    # Add metadata
    documents = processor.add_metadata(documents, {
        "processed_date": "2024-01-01",
        "version": "1.0"
    })
    
    # Create vectorstore
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=rag_agent.embeddings,
        persist_directory="./production_db"
    )
    
    # Setup advanced retriever
    base_retriever = vectorstore.as_retriever()
    compressed_retriever = rag_agent.setup_contextual_compression(base_retriever)
    
    # Create final chain
    qa_chain = rag_agent.create_rag_chain_with_sources(compressed_retriever)
    
    logger.info("Production RAG system ready")
    return qa_chain

# Usage
if __name__ == "__main__":
    qa_system = setup_production_rag()
    result = qa_system({"question": "How do I deploy the system?"})
    print(f"Answer: {result['answer']}")
    print(f"Sources: {result['sources']}")
#+END_SRC

** 15-min Review Questions:
1. What are the key components of a RAG system?
2. How does contextual compression improve retrieval quality?
3. When should you use hybrid retrieval vs single-mode retrieval?

* Session 7: Agent Orchestration & Multi-Agent Systems (2 hours)
*Focus:* Coordinating multiple agents and complex workflows

** Hour 1: Multi-Agent Architecture

#+BEGIN_SRC python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
from enum import Enum
import asyncio
import json
from dataclasses import dataclass, asdict
from datetime import datetime

class MessageType(Enum):
    TASK_REQUEST = "task_request"
    TASK_RESPONSE = "task_response"
    COORDINATION = "coordination"
    STATUS_UPDATE = "status_update"

@dataclass
class Message:
    sender: str
    receiver: str
    message_type: MessageType
    content: Dict[str, Any]
    timestamp: str
    message_id: str

class MessageBus:
    """Central message bus for agent communication"""
    
    def __init__(self):
        self.subscribers: Dict[str, List[callable]] = {}
        self.message_history: List[Message] = []
    
    def subscribe(self, agent_id: str, callback: callable):
        """Subscribe agent to message bus"""
        if agent_id not in self.subscribers:
            self.subscribers[agent_id] = []
        self.subscribers[agent_id].append(callback)
    
    def publish(self, message: Message):
        """Publish message to subscribers"""
        self.message_history.append(message)
        
        if message.receiver in self.subscribers:
            for callback in self.subscribers[message.receiver]:
                callback(message)
        
        # Broadcast messages (receiver = "all")
        if message.receiver == "all":
            for agent_id, callbacks in self.subscribers.items():
                if agent_id != message.sender:
                    for callback in callbacks:
                        callback(message)

class BaseAgent(ABC):
    """Base class for all agents in the system"""
    
    def __init__(self, agent_id: str, message_bus: MessageBus, capabilities: List[str]):
        self.agent_id = agent_id
        self.capabilities = capabilities
        self.message_bus = message_bus
        self.status = "idle"
        self.current_task = None
        
        # Subscribe to message bus
        self.message_bus.subscribe(self.agent_id, self.handle_message)
    
    @abstractmethod
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process a specific task"""
        pass
    
    def handle_message(self, message: Message):
        """Handle incoming messages"""
        if message.message_type == MessageType.TASK_REQUEST:
            asyncio.create_task(self._handle_task_request(message))
        elif message.message_type == MessageType.COORDINATION:
            self._handle_coordination(message)
    
    async def _handle_task_request(self, message: Message):
        """Handle task request message"""
        task = message.content
        
        if self._can_handle_task(task):
            self.status = "working"
            self.current_task = task
            
            try:
                result = await self.process_task(task)
                
                response = Message(
                    sender=self.agent_id,
                    receiver=message.sender,
                    message_type=MessageType.TASK_RESPONSE,
                    content={"result": result, "status": "completed"},
                    timestamp=str(datetime.now()),
                    message_id=f"{self.agent_id}_{datetime.now().timestamp()}"
                )
                
                self.message_bus.publish(response)
                
            except Exception as e:
                error_response = Message(
                    sender=self.agent_id,
                    receiver=message.sender,
                    message_type=MessageType.TASK_RESPONSE,
                    content={"error": str(e), "status": "failed"},
                    timestamp=str(datetime.now()),
                    message_id=f"{self.agent_id}_{datetime.now().timestamp()}"
                )
                self.message_bus.publish(error_response)
            
            finally:
                self.status = "idle"
                self.current_task = None
    
    def _can_handle_task(self, task: Dict[str, Any]) -> bool:
        """Check if agent can handle the task"""
        required_capability = task.get("required_capability")
        return required_capability in self.capabilities
    
    def _handle_coordination(self, message: Message):
        """Handle coordination messages"""
        pass
    
    def send_message(self, receiver: str, message_type: MessageType, content: Dict[str, Any]):
        """Send message to another agent"""
        message = Message(
            sender=self.agent_id,
            receiver=receiver,
            message_type=message_type,
            content=content,
            timestamp=str(datetime.now()),
            message_id=f"{self.agent_id}_{datetime.now().timestamp()}"
        )
        self.message_bus.publish(message)

# Specific agent implementations
class ResearchAgent(BaseAgent):
    """Agent specialized in research tasks"""
    
    def __init__(self, agent_id: str, message_bus: MessageBus, llm_client):
        super().__init__(agent_id, message_bus, ["research", "web_search", "summarization"])
        self.llm = llm_client
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process research task"""
        query = task.get("query", "")
        task_type = task.get("type", "research")
        
        if task_type == "research":
            return await self._conduct_research(query)
        elif task_type == "summarization":
            return await self._summarize_content(task.get("content", ""))
        
        return {"error": "Unknown research task type"}
    
    async def _conduct_research(self, query: str) -> Dict[str, Any]:
        """Conduct research on a topic"""
        # Mock research implementation
        await asyncio.sleep(2)  # Simulate research time
        
        research_result = f"Research findings for '{query}': Comprehensive analysis completed"
        
        return {
            "type": "research_result",
            "query": query,
            "findings": research_result,
            "sources": ["source1.com", "source2.com"],
            "timestamp": str(datetime.now())
        }
    
    async def _summarize_content(self, content: str) -> Dict[str, Any]:
        """Summarize content"""
        # Use LLM for summarization
        summary = f"Summary of content: {content[:100]}..."
        
        return {
            "type": "summary",
            "original_length": len(content),
            "summary": summary,
            "compression_ratio": len(summary) / len(content)
        }

class WritingAgent(BaseAgent):
    """Agent specialized in writing tasks"""
    
    def __init__(self, agent_id: str, message_bus: MessageBus, llm_client):
        super().__init__(agent_id, message_bus, ["writing", "editing", "content_creation"])
        self.llm = llm_client
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process writing task"""
        task_type = task.get("type", "write")
        
        if task_type == "write":
            return await self._write_content(task)
        elif task_type == "edit":
            return await self._edit_content(task)
        
        return {"error": "Unknown writing task type"}
    
    async def _write_content(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Write content based on requirements"""
        topic = task.get("topic", "")
        style = task.get("style", "informative")
        length = task.get("length", "medium")
        
        # Mock writing implementation
        await asyncio.sleep(3)  # Simulate writing time
        
        content = f"Written content about '{topic}' in {style} style, {length} length"
        
        return {
            "type": "written_content",
            "topic": topic,
            "content": content,
            "word_count": len(content.split()),
            "style": style
        }
    
    async def _edit_content(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Edit existing content"""
        original_content = task.get("content", "")
        edit_type = task.get("edit_type", "grammar")
        
        # Mock editing implementation
        edited_content = f"[EDITED] {original_content}"
        
        return {
            "type": "edited_content",
            "original": original_content,
            "edited": edited_content,
            "changes_made": [f"{edit_type} corrections applied"]
        }

class CoordinatorAgent(BaseAgent):
    """Agent that coordinates tasks between other agents"""
    
    def __init__(self, agent_id: str, message_bus: MessageBus):
        super().__init__(agent_id, message_bus, ["coordination", "task_planning", "workflow_management"])
        self.active_workflows: Dict[str, Dict] = {}
        self.agent_capabilities: Dict[str, List[str]] = {}
    
    def register_agent(self, agent_id: str, capabilities: List[str]):
        """Register an agent and its capabilities"""
        self.agent_capabilities[agent_id] = capabilities
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process coordination task"""
        if task.get("type") == "complex_workflow":
            return await self._execute_complex_workflow(task)
        elif task.get("type") == "simple_delegation":
            return await self._delegate_simple_task(task)
        
        return {"error": "Unknown coordination task type"}
    
    async def _execute_complex_workflow(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a complex multi-step workflow"""
        workflow_id = f"workflow_{datetime.now().timestamp()}"
        steps = task.get("steps", [])
        
        self.active_workflows[workflow_id] = {
            "steps": steps,
            "current_step": 0,
            "results": [],
            "status": "running"
        }
        
        results = []
        
        for i, step in enumerate(steps):
            # Find capable agent
            capable_agent = self._find_capable_agent(step.get("required_capability"))
            
            if not capable_agent:
                return {"error": f"No agent capable of handling step {i+1}"}
            
            # Send task to agent
            self.send_message(
                receiver=capable_agent,
                message_type=MessageType.TASK_REQUEST,
                content=step
            )
            
            # Wait for response (simplified - in production, use proper async handling)
            await asyncio.sleep(5)  # Mock wait time
            
            # Mock result collection
            result = {"step": i+1, "status": "completed", "agent": capable_agent}
            results.append(result)
        
        self.active_workflows[workflow_id]["status"] = "completed"
        self.active_workflows[workflow_id]["results"] = results
        
        return {
            "workflow_id": workflow_id,
            "status": "completed",
            "results": results
        }
    
    async def _delegate_simple_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Delegate a simple task to appropriate agent"""
        required_capability = task.get("required_capability")
        capable_agent = self._find_capable_agent(required_capability)
        
        if not capable_agent:
            return {"error": f"No agent capable of handling {required_capability}"}
        
        self.send_message(
            receiver=capable_agent,
            message_type=MessageType.TASK_REQUEST,
            content=task
        )
        
        return {
            "status": "delegated",
            "assigned_agent": capable_agent,
            "task_id": task.get("id", "unknown")
        }
    
    def _find_capable_agent(self, required_capability: str) -> Optional[str]:
        """Find an agent capable of handling the required capability"""
        for agent_id, capabilities in self.agent_capabilities.items():
            if required_capability in capabilities:
                return agent_id
        return None

# Multi-agent system setup
class MultiAgentSystem:
    """Main system that manages all agents"""
    
    def __init__(self):
        self.message_bus = MessageBus()
        self.agents: Dict[str, BaseAgent] = {}
        self.coordinator = None
    
    def add_agent(self, agent: BaseAgent):
        """Add an agent to the system"""
        self.agents[agent.agent_id] = agent
        
        # Register with coordinator if exists
        if self.coordinator:
            self.coordinator.register_agent(agent.agent_id, agent.capabilities)
    
    def set_coordinator(self, coordinator: CoordinatorAgent):
        """Set the coordinator agent"""
        self.coordinator = coordinator
        self.add_agent(coordinator)
        
        # Register all existing agents with coordinator
        for agent in self.agents.values():
            if agent.agent_id != coordinator.agent_id:
                coordinator.register_agent(agent.agent_id, agent.capabilities)
    
    async def execute_complex_task(self, task_description: str) -> Dict[str, Any]:
        """Execute a complex task using multiple agents"""
        if not self.coordinator:
            return {"error": "No coordinator available"}
        
        # Parse task into workflow steps (simplified)
        workflow_task = {
            "type": "complex_workflow",
            "description": task_description,
            "steps": [
                {"required_capability": "research", "query": task_description},
                {"required_capability": "writing", "topic": task_description, "type": "write"}
            ]
        }
        
        result = await self.coordinator.process_task(workflow_task)
        return result
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get status of all agents in the system"""
        status = {}
        for agent_id, agent in self.agents.items():
            status[agent_id] = {
                "status": agent.status,
                "capabilities": agent.capabilities,
                "current_task": agent.current_task
            }
        return status

# Usage example
async def setup_multi_agent_system():
    """Setup and run multi-agent system"""
    # Create system
    mas = MultiAgentSystem()
    
    # Create agents
    research_agent = ResearchAgent("researcher_1", mas.message_bus, None)  # llm_client would go here
    writing_agent = WritingAgent("writer_1", mas.message_bus, None)
    coordinator = CoordinatorAgent("coordinator", mas.message_bus)
    
    # Add agents to system
    mas.add_agent(research_agent)
    mas.add_agent(writing_agent)
    mas.set_coordinator(coordinator)
    
    # Execute complex task
    result = await mas.execute_complex_task("Write a report on AI agent architectures")
    
    print(f"Task result: {result}")
    print(f"System status: {mas.get_system_status()}")
    
    return mas

if __name__ == "__main__":
    asyncio.run(setup_multi_agent_system())
#+END_SRC

** Hour 2: CrewAI and Advanced Orchestration

#+BEGIN_SRC python
# CrewAI implementation example
from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field

class SearchToolInput(BaseModel):
    """Input schema for SearchTool."""
    search_query: str = Field(..., description="The search query to find information")

class SearchTool(BaseTool):
    name: str = "search_tool"
    description: str = "Search for information on the internet"
    args_schema: Type[BaseModel] = SearchToolInput

    def _run(self, search_query: str) -> str:
        # Mock search implementation
        return f"Search results for '{search_query}': Relevant information found"

class CalculatorTool(BaseTool):
    name: str = "calculator"
    description: str = "Perform mathematical calculations"
    
    def _run(self, expression: str) -> str:
        try:
            result = eval(expression)  # Use safe evaluator in production
            return f"The result of {expression} is {result}"
        except Exception as e:
            return f"Calculation error: {str(e)}"

class CrewAISystem:
    def __init__(self):
        self.search_tool = SearchTool()
        self.calculator_tool = CalculatorTool()
        self.agents = self._create_agents()
    
    def _create_agents(self):
        """Create specialized agents"""
        
        # Research Agent
        researcher = Agent(
            role='Senior Research Analyst',
            goal='Uncover cutting-edge developments in AI and data science',
            backstory="""You work at a leading tech think tank.
            Your expertise lies in identifying emerging trends.
            You have a knack for dissecting complex data and presenting actionable insights.""",
            verbose=True,
            allow_delegation=False,
            tools=[self.search_tool]
        )
        
        # Writer Agent
        writer = Agent(
            role='Tech Content Strategist',
            goal='Craft compelling content on tech advancements',
            backstory="""You are a renowned Content Strategist, known for your insightful
            and engaging articles. You transform complex concepts into compelling narratives.""",
            verbose=True,
            allow_delegation=True
        )
        
        # Data Analyst Agent
        analyst = Agent(
            role='Data Analyst',
            goal='Analyze data and provide statistical insights',
            backstory="""You are an expert data analyst with a keen eye for patterns
            and statistical significance. You excel at turning raw data into actionable insights.""",
            verbose=True,
            allow_delegation=False,
            tools=[self.calculator_tool]
        )
        
        return {
            'researcher': researcher,
            'writer': writer,
            'analyst': analyst
        }
    
    def create_research_crew(self, topic: str):
        """Create a crew for research tasks"""
        
        # Define tasks
        research_task = Task(
            description=f"""Conduct a comprehensive analysis of {topic}.
            Focus on the latest developments, key players, and future implications.
            Your final answer MUST be a detailed report with key findings.""",
            expected_output="A comprehensive research report with key findings and insights",
            agent=self.agents['researcher']
        )
        
        analysis_task = Task(
            description=f"""Using the research findings, perform statistical analysis
            and identify key trends and patterns related to {topic}.""",
            expected_output="Statistical analysis with trends and patterns identified",
            agent=self.agents['analyst']
        )
        
        writing_task = Task(
            description=f"""Using the research and analysis, create a compelling article
            about {topic} that is engaging and informative for a general audience.""",
            expected_output="A well-written article suitable for publication",
            agent=self.agents['writer']
        )
        
        # Create crew
        crew = Crew(
            agents=[self.agents['researcher'], self.agents['analyst'], self.agents['writer']],
            tasks=[research_task, analysis_task, writing_task],
            verbose=2,
            process=Process.sequential
        )
        
        return crew
    
    def execute_parallel_crew(self, topics: list):
        """Execute multiple crews in parallel"""
        import concurrent.futures
        
        def run_crew(topic):
            crew = self.create_research_crew(topic)
            return crew.kickoff()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            future_to_topic = {executor.submit(run_crew, topic): topic for topic in topics}
            results = {}
            
            for future in concurrent.futures.as_completed(future_to_topic):
                topic = future_to_topic[future]
                try:
                    result = future.result()
                    results[topic] = result
                except Exception as exc:
                    results[topic] = f"Error: {exc}"
        
        return results

# LangGraph implementation for complex workflows
from langgraph.graph import Graph, StateGraph, END
from langgraph.prebuilt import ToolExecutor, ToolInvocation
from typing import TypedDict, Annotated, Sequence
import operator

class AgentState(TypedDict):
    messages: Annotated[Sequence[str], operator.add]
    current_step: str
    results: dict
    error: str

class LangGraphOrchestrator:
    def __init__(self):
        self.tools = self._setup_tools()
        self.tool_executor = ToolExecutor(self.tools)
    
    def _setup_tools(self):
        """Setup tools for the workflow"""
        def research_tool(query: str) -> str:
            return f"Research completed for: {query}"
        
        def analysis_tool(data: str) -> str:
            return f"Analysis completed for: {data}"
        
        def writing_tool(content: str) -> str:
            return f"Article written based on: {content}"
        
        return [research_tool, analysis_tool, writing_tool]
    
    def research_node(self, state: AgentState):
        """Research node in the workflow"""
        messages = state.get('messages', [])
        
        # Perform research
        research_result = "Research findings: Comprehensive data collected"
        
        return {
            "messages": messages + [research_result],
            "current_step": "research_completed",
            "results": {**state.get('results', {}), "research": research_result}
        }
    
    def analysis_node(self, state: AgentState):
        """Analysis node in the workflow"""
        messages = state.get('messages', [])
        research_data = state.get('results', {}).get('research', '')
        
        # Perform analysis
        analysis_result = f"Analysis complete: {research_data} analyzed"
        
        return {
            "messages": messages + [analysis_result],
            "current_step": "analysis_completed",
            "results": {**state.get('results', {}), "analysis": analysis_result}
        }
    
    def writing_node(self, state: AgentState):
        """Writing node in the workflow"""
        messages = state.get('messages', [])
        analysis_data = state.get('results', {}).get('analysis', '')
        
        # Perform writing
        writing_result = f"Article completed based on: {analysis_data}"
        
        return {
            "messages": messages + [writing_result],
            "current_step": "writing_completed",
            "results": {**state.get('results', {}), "writing": writing_result}
        }
    
    def should_continue(self, state: AgentState):
        """Determine if workflow should continue"""
        current_step = state.get('current_step', '')
        
        if current_step == "research_completed":
            return "analysis"
        elif current_step == "analysis_completed":
            return "writing"
        elif current_step == "writing_completed":
            return END
        else:
            return "research"
    
    def create_workflow(self):
        """Create the LangGraph workflow"""
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("research", self.research_node)
        workflow.add_node("analysis", self.analysis_node)
        workflow.add_node("writing", self.writing_node)
        
        # Add edges
        workflow.set_entry_point("research")
        
        workflow.add_conditional_edges(
            "research",
            self.should_continue,
            {
                "analysis": "analysis",
                END: END
            }
        )
        
        workflow.add_conditional_edges(
            "analysis",
            self.should_continue,
            {
                "writing": "writing",
                END: END
            }
        )
        
        workflow.add_conditional_edges(
            "writing",
            self.should_continue,
            {
                END: END
            }
        )
        
        return workflow.compile()
    
    def execute_workflow(self, initial_query: str):
        """Execute the complete workflow"""
        app = self.create_workflow()
        
        initial_state = {
            "messages": [f"Starting workflow for: {initial_query}"],
            "current_step": "start",
            "results": {},
            "error": ""
        }
        
        result = app.invoke(initial_state)
        return result

# Advanced orchestration patterns
class WorkflowManager:
    def __init__(self):
        self.active_workflows = {}
        self.completed_workflows = {}
        self.workflow_templates = self._create_templates()
    
    def _create_templates(self):
        """Create workflow templates"""
        return {
            "content_creation": {
                "steps": ["research", "analysis", "writing", "review"],
                "parallel_allowed": ["research", "analysis"],
                "dependencies": {
                    "analysis": ["research"],
                    "writing": ["research", "analysis"],
                    "review": ["writing"]
                }
            },
            "data_processing": {
                "steps": ["collection", "cleaning", "analysis", "visualization"],
                "parallel_allowed": ["cleaning", "analysis"],
                "dependencies": {
                    "cleaning": ["collection"],
                    "analysis": ["cleaning"],
                    "visualization": ["analysis"]
                }
            }
        }
    
    def create_dynamic_workflow(self, template_name: str, parameters: dict):
        """Create a dynamic workflow from template"""
        if template_name not in self.workflow_templates:
            raise ValueError(f"Template {template_name} not found")
        
        template = self.workflow_templates[template_name]
        workflow_id = f"{template_name}_{len(self.active_workflows)}"
        
        workflow = {
            "id": workflow_id,
            "template": template_name,
            "steps": template["steps"].copy(),
            "current_step": 0,
            "parameters": parameters,
            "status": "created",
            "results": {},
            "start_time": datetime.now(),
            "dependencies": template["dependencies"]
        }
        
        self.active_workflows[workflow_id] = workflow
        return workflow_id
    
    async def execute_workflow(self, workflow_id: str):
        """Execute a workflow with dependency management"""
        if workflow_id not in self.active_workflows:
            raise ValueError(f"Workflow {workflow_id} not found")
        
        workflow = self.active_workflows[workflow_id]
        workflow["status"] = "running"
        
        completed_steps = set()
        
        while len(completed_steps) < len(workflow["steps"]):
            # Find steps that can be executed (dependencies met)
            executable_steps = []
            
            for step in workflow["steps"]:
                if step not in completed_steps:
                    dependencies = workflow["dependencies"].get(step, [])
                    if all(dep in completed_steps for dep in dependencies):
                        executable_steps.append(step)
            
            if not executable_steps:
                break  # No more steps can be executed
            
            # Execute steps (potentially in parallel)
            for step in executable_steps:
                result = await self._execute_step(step, workflow["parameters"])
                workflow["results"][step] = result
                completed_steps.add(step)
        
        workflow["status"] = "completed"
        workflow["end_time"] = datetime.now()
        
        # Move to completed workflows
        self.completed_workflows[workflow_id] = workflow
        del self.active_workflows[workflow_id]
        
        return workflow
    
    async def _execute_step(self, step: str, parameters: dict):
        """Execute a single workflow step"""
        # Mock step execution
        await asyncio.sleep(1)  # Simulate processing time
        return f"Step {step} completed with parameters: {parameters}"
    
    def get_workflow_status(self, workflow_id: str):
        """Get status of a workflow"""
        if workflow_id in self.active_workflows:
            return self.active_workflows[workflow_id]
        elif workflow_id in self.completed_workflows:
            return self.completed_workflows[workflow_id]
        else:
            return None

# Usage examples
async def orchestration_examples():
    """Examples of different orchestration patterns"""
    
    # 1. CrewAI example
    print("=== CrewAI Example ===")
    crew_system = CrewAISystem()
    crew = crew_system.create_research_crew("Artificial Intelligence")
    # result = crew.kickoff()  # Uncomment when CrewAI is properly installed
    
    # 2. LangGraph example
    print("=== LangGraph Example ===")
    langgraph_orchestrator = LangGraphOrchestrator()
    workflow_result = langgraph_orchestrator.execute_workflow("AI agent architectures")
    print(f"LangGraph result: {workflow_result}")
    
    # 3. Dynamic workflow example
    print("=== Dynamic Workflow Example ===")
    workflow_manager = WorkflowManager()
    workflow_id = workflow_manager.create_dynamic_workflow(
        "content_creation", 
        {"topic": "AI trends", "target_audience": "technical"}
    )
    
    result = await workflow_manager.execute_workflow(workflow_id)
    print(f"Dynamic workflow result: {result}")

if __name__ == "__main__":
    asyncio.run(orchestration_examples())
#+END_SRC

** 15-min Review Questions:
1. What are the key benefits of multi-agent systems over single agents?
2. How do you handle coordination and communication between agents?
3. When should you use sequential vs parallel agent execution?

* Session 8: Memory Management & Persistence (2 hours)
*Focus:* Managing agent memory and state across conversations

** Hour 1: Memory Systems Architecture

#+BEGIN_SRC python
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Tuple
import json
import sqlite3
import pickle
import hashlib
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import deque
import redis
import chromadb

@dataclass
class MemoryEntry:
    id: str
    content: str
    metadata: Dict[str, Any]
    timestamp: datetime
    memory_type: str
    importance: float
    access_count: int = 0
    last_accessed: Optional[datetime] = None

class BaseMemory(ABC):
    """Base class for all memory implementations"""
    
    @abstractmethod
    def store(self, content: str, metadata: Dict[str, Any], memory_type: str = "episodic") -> str:
        """Store a memory entry"""
        pass
    
    @abstractmethod
    def retrieve(self, query: str, k: int = 5) -> List[MemoryEntry]:
        """Retrieve relevant memories"""
        pass
    
    @abstractmethod
    def update(self, memory_id: str, content: str = None, metadata: Dict[str, Any] = None) -> bool:
        """Update an existing memory"""
        pass
    
    @abstractmethod
    def delete(self, memory_id: str) -> bool:
        """Delete a memory entry"""
        pass

class ShortTermMemory(BaseMemory):
    """Working memory for current conversation"""
    
    def __init__(self, max_size: int = 50):
        self.max_size = max_size
        self.memories: deque = deque(maxlen=max_size)
        self.memory_index: Dict[str, MemoryEntry] = {}
    
    def store(self, content: str, metadata: Dict[str, Any], memory_type: str = "working") -> str:
        """Store in short-term memory"""
        memory_id = self._generate_id(content)
        
        memory_entry = MemoryEntry(
            id=memory_id,
            content=content,
            metadata=metadata,
            timestamp=datetime.now(),
            memory_type=memory_type,
            importance=metadata.get("importance", 0.5)
        )
        
        # Remove oldest if at capacity
        if len(self.memories) >= self.max_size:
            old_memory = self.memories.popleft()
            del self.memory_index[old_memory.id]
        
        self.memories.append(memory_entry)
        self.memory_index[memory_id] = memory_entry
        
        return memory_id
    
    def retrieve(self, query: str, k: int = 5) -> List[MemoryEntry]:
        """Retrieve from short-term memory based on recency and relevance"""
        memories = list(self.memories)
        
        # Simple relevance scoring (keyword matching)
        scored_memories = []
        query_words = set(query.lower().split())
        
        for memory in memories:
            content_words = set(memory.content.lower().split())
            relevance = len(query_words.intersection(content_words)) / max(len(query_words), 1)
            
            # Combine relevance with recency
            time_decay = self._calculate_time_decay(memory.timestamp)
            score = relevance * 0.7 + time_decay * 0.3
            
            scored_memories.append((score, memory))
        
        # Sort by score and return top k
        scored_memories.sort(key=lambda x: x[0], reverse=True)
        return [memory for _, memory in scored_memories[:k]]
    
    def update(self, memory_id: str, content: str = None, metadata: Dict[str, Any] = None) -> bool:
        """Update short-term memory"""
        if memory_id not in self.memory_index:
            return False
        
        memory = self.memory_index[memory_id]
        
        if content:
            memory.content = content
        if metadata:
            memory.metadata.update(metadata)
        
        memory.access_count += 1
        memory.last_accessed = datetime.now()
        
        return True
    
    def delete(self, memory_id: str) -> bool:
        """Delete from short-term memory"""
        if memory_id not in self.memory_index:
            return False
        
        memory = self.memory_index[memory_id]
        self.memories.remove(memory)
        del self.memory_index[memory_id]
        
        return True
    
    def _generate_id(self, content: str) -> str:
        """Generate unique ID for memory entry"""
        return hashlib.md5(f"{content}{datetime.now()}".encode()).hexdigest()[:16]
    
    def _calculate_time_decay(self, timestamp: datetime) -> float:
        """Calculate time decay factor (1.0 = recent, 0.0 = old)"""
        now = datetime.now()
        diff = (now - timestamp).total_seconds()
        max_age = 3600  # 1 hour
        return max(0, 1 - (diff / max_age))
    
    def get_conversation_summary(self) -> str:
        """Get summary of current conversation"""
        if not self.memories:
            return "No conversation history"
        
        recent_memories = list(self.memories)[-10:]  # Last 10 entries
        summary_parts = [memory.content for memory in recent_memories]
        
        return " | ".join(summary_parts)

class LongTermMemory(BaseMemory):
    """Persistent memory stored in database"""
    
    def __init__(self, db_path: str = "agent_memory.db"):
        self.db_path = db_path
        self._init_database()
    
    def _init_database(self):
        """Initialize SQLite database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memories (
                id TEXT PRIMARY KEY,
                content TEXT NOT NULL,
                metadata TEXT,
                timestamp TEXT,
                memory_type TEXT,
                importance REAL,
                access_count INTEGER DEFAULT 0,
                last_accessed TEXT
            )
        ''')
        
        # Create index for faster searches
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_memory_type ON memories(memory_type)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON memories(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_importance ON memories(importance)')
        
        conn.commit()
        conn.close()
    
    def store(self, content: str, metadata: Dict[str, Any], memory_type: str = "episodic") -> str:
        """Store in long-term memory"""
        memory_id = self._generate_id(content)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO memories 
            (id, content, metadata, timestamp, memory_type, importance)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            memory_id,
            content,
            json.dumps(metadata),
            datetime.now().isoformat(),
            memory_type,
            metadata.get("importance", 0.5)
        ))
        
        conn.commit()
        conn.close()
        
        return memory_id
    
    def retrieve(self, query: str, k: int = 5, memory_type: str = None) -> List[MemoryEntry]:
        """Retrieve from long-term memory with semantic search"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Build query
        sql_query = '''
            SELECT id, content, metadata, timestamp, memory_type, importance, access_count, last_accessed
            FROM memories
        '''
        params = []
        
        if memory_type:
            sql_query += ' WHERE memory_type = ?'
            params.append(memory_type)
        
        sql_query += ' ORDER BY importance DESC, timestamp DESC LIMIT ?'
        params.append(k * 2)  # Get more to filter
        
        cursor.execute(sql_query, params)
        results = cursor.fetchall()
        conn.close()
        
        # Convert to MemoryEntry objects and score
        memories = []
        for row in results:
            memory = MemoryEntry(
                id=row[0],
                content=row[1],
                metadata=json.loads(row[2]),
                timestamp=datetime.fromisoformat(row[3]),
                memory_type=row[4],
                importance=row[5],
                access_count=row[6],
                last_accessed=datetime.fromisoformat(row[7]) if row[7] else None
            )
            memories.append(memory)
        
        # Simple relevance scoring
        scored_memories = self._score_memories(memories, query)
        return scored_memories[:k]
    
    def update(self, memory_id: str, content: str = None, metadata: Dict[str, Any] = None) -> bool:
        """Update long-term memory"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # First, get current memory
        cursor.execute('SELECT * FROM memories WHERE id = ?', (memory_id,))
        result = cursor.fetchone()
        
        if not result:
            conn.close()
            return False
        
        # Update fields
        new_content = content if content else result[1]
        current_metadata = json.loads(result[2])
        if metadata:
            current_metadata.update(metadata)
        
        cursor.execute('''
            UPDATE memories 
            SET content = ?, metadata = ?, access_count = access_count + 1, last_accessed = ?
            WHERE id = ?
        ''', (new_content, json.dumps(current_metadata), datetime.now().isoformat(), memory_id))
        
        conn.commit()
        conn.close()
        
        return True
    
    def delete(self, memory_id: str) -> bool:
        """Delete from long-term memory"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('DELETE FROM memories WHERE id = ?', (memory_id,))
        deleted = cursor.rowcount > 0
        
        conn.commit()
        conn.close()
        
        return deleted
    
    def _generate_id(self, content: str) -> str:
        """Generate unique ID"""
        return hashlib.sha256(f"{content}{datetime.now()}".encode()).hexdigest()[:32]
    
    def _score_memories(self, memories: List[MemoryEntry], query: str) -> List[MemoryEntry]:
        """Score memories based on relevance to query"""
        query_words = set(query.lower().split())
        scored_memories = []
        
        for memory in memories:
            content_words = set(memory.content.lower().split())
            relevance = len(query_words.intersection(content_words)) / max(len(query_words), 1)
            
            # Combine multiple factors
            importance_score = memory.importance
            recency_score = self._calculate_recency_score(memory.timestamp)
            access_score = min(memory.access_count / 10.0, 1.0)  # Normalize access count
            
            total_score = (relevance * 0.4 + importance_score * 0.3 + 
                          recency_score * 0.2 + access_score * 0.1)
            
            scored_memories.append((total_score, memory))
        
        scored_memories.sort(key=lambda x: x[0], reverse=True)
        return [memory for _, memory in scored_memories]
    
    def _calculate_recency_score(self, timestamp: datetime) -> float:
        """Calculate recency score"""
        now = datetime.now()
        diff = (now - timestamp).days
        return max(0, 1 - (diff / 365))  # Decay over a year

class VectorMemory(BaseMemory):
    """Vector-based semantic memory using embeddings"""
    
    def __init__(self, collection_name: str = "agent_memory"):
        self.client = chromadb.Client()
        self.collection = self.client.get_or_create_collection(name=collection_name)
        self.metadata_store = {}  # Additional metadata storage
    
    def store(self, content: str, metadata: Dict[str, Any], memory_type: str = "semantic") -> str:
        """Store with vector embeddings"""
        memory_id = self._generate_id(content)
        
        # Store in vector database
        self.collection.add(
            documents=[content],
            metadatas=[{
                "memory_type": memory_type,
                "timestamp": datetime.now().isoformat(),
                "importance": metadata.get("importance", 0.5)
            }],
            ids=[memory_id]
        )
        
        # Store full metadata separately
        self.metadata_store[memory_id] = MemoryEntry(
            id=memory_id,
            content=content,
            metadata=metadata,
            timestamp=datetime.now(),
            memory_type=memory_type,
            importance=metadata.get("importance", 0.5)
        )
        
        return memory_id
    
    def retrieve(self, query: str, k: int = 5) -> List[MemoryEntry]:
        """Retrieve using semantic similarity"""
        results = self.collection.query(
            query_texts=[query],
            n_results=k
        )
        
        memories = []
        for i, memory_id in enumerate(results['ids'][0]):
            if memory_id in self.metadata_store:
                memory = self.metadata_store[memory_id]
                memory.access_count += 1
                memory.last_accessed = datetime.now()
                memories.append(memory)
        
        return memories
    
    def update(self, memory_id: str, content: str = None, metadata: Dict[str, Any] = None) -> bool:
        """Update vector memory"""
        if memory_id not in self.metadata_store:
            return False
        
        memory = self.metadata_store[memory_id]
        
        if content:
            # Update vector database
            self.collection.update(
                ids=[memory_id],
                documents=[content]
            )
            memory.content = content
        
        if metadata:
            memory.metadata.update(metadata)
        
        return True
    
    def delete(self, memory_id: str) -> bool:
        """Delete from vector memory"""
        if memory_id not in self.metadata_store:
            return False
        
        self.collection.delete(ids=[memory_id])
        del self.metadata_store[memory_id]
        
        return True
    
    def _generate_id(self, content: str) -> str:
        """Generate unique ID"""
        return hashlib.md5(f"{content}{datetime.now()}".encode()).hexdigest()

class HybridMemorySystem:
    """Combines multiple memory types for comprehensive memory management"""
    
    def __init__(self):
        self.short_term = ShortTermMemory(max_size=50)
        self.long_term = LongTermMemory("agent_memory.db")
        self.vector_memory = VectorMemory("agent_semantic_memory")
        
        # Memory consolidation settings
        self.consolidation_threshold = 5  # Access count threshold
        self.consolidation_interval = 3600  # 1 hour in seconds
        self.last_consolidation = datetime.now()
    
    def store_memory(self, content: str, metadata: Dict[str, Any], memory_type: str = "episodic"):
        """Store memory in appropriate system(s)"""
        importance = metadata.get("importance", 0.5)
        
        # Always store in short-term memory
        short_term_id = self.short_term.store(content, metadata, memory_type)
        
        # Store important memories in long-term immediately
        if importance > 0.7:
            long_term_id = self.long_term.store(content, metadata, memory_type)
            self.vector_memory.store(content, metadata, memory_type)
            return long_term_id
        
        return short_term_id
    
    def retrieve_memory(self, query: str, k: int = 5, memory_types: List[str] = None) -> List[MemoryEntry]:
        """Retrieve from all memory systems and merge results"""
        all_memories = []
        
        # Get from short-term memory
        short_term_memories = self.short_term.retrieve(query, k)
        all_memories.extend(short_term_memories)
        
        # Get from long-term memory
        for memory_type in (memory_types or ["episodic", "semantic", "procedural"]):
            long_term_memories = self.long_term.retrieve(query, k//2, memory_type)
            all_memories.extend(long_term_memories)
        
        # Get from vector memory
        vector_memories = self.vector_memory.retrieve(query, k)
        all_memories.extend(vector_memories)
        
        # Remove duplicates and score
        unique_memories = {memory.id: memory for memory in all_memories}
        scored_memories = self._score_hybrid_memories(list(unique_memories.values()), query)
        
        return scored_memories[:k]
    
    def consolidate_memories(self):
        """Consolidate important short-term memories to long-term"""
        current_time = datetime.now()
        
        if (current_time - self.last_consolidation).seconds < self.consolidation_interval:
            return
        
        # Find memories to consolidate
        consolidation_candidates = []
        
        for memory in self.short_term.memories:
            if (memory.access_count >= self.consolidation_threshold or 
                memory.importance > 0.6):
                consolidation_candidates.append(memory)
        
        # Move to long-term storage
        for memory in consolidation_candidates:
            self.long_term.store(memory.content, memory.metadata, memory.memory_type)
            
            # Also store in vector memory for semantic search
            if memory.memory_type in ["episodic", "semantic"]:
                self.vector_memory.store(memory.content, memory.metadata, memory.memory_type)
        
        self.last_consolidation = current_time
        
        return len(consolidation_candidates)
    
    def _score_hybrid_memories(self, memories: List[MemoryEntry], query: str) -> List[MemoryEntry]:
        """Score memories from hybrid system"""
        query_words = set(query.lower().split())
        scored_memories = []
        
        for memory in memories:
            content_words = set(memory.content.lower().split())
            relevance = len(query_words.intersection(content_words)) / max(len(query_words), 1)
            
            # Memory type bonuses
            type_bonus = {
                "working": 0.8,  # Recent working memory
                "episodic": 0.6,
                "semantic": 0.7,
                "procedural": 0.5
            }.get(memory.memory_type, 0.5)
            
            # Access pattern bonus
            access_bonus = min(memory.access_count / 10.0, 0.3)
            
            total_score = (relevance * 0.5 + memory.importance * 0.3 + 
                          type_bonus * 0.1 + access_bonus * 0.1)
            
            scored_memories.append((total_score, memory))
        
        scored_memories.sort(key=lambda x: x[0], reverse=True)
        return [memory for _, memory in scored_memories]
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Get statistics about memory usage"""
        return {
            "short_term_count": len(self.short_term.memories),
            "short_term_capacity": self.short_term.max_size,
            "vector_memory_count": len(self.vector_memory.metadata_store),
            "last_consolidation": self.last_consolidation.isoformat()
        }

# Usage example
class MemoryAwareAgent:
    """Agent with comprehensive memory management"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.memory_system = HybridMemorySystem()
        self.conversation_id = None
    
    def start_conversation(self, conversation_id: str = None):
        """Start a new conversation"""
        self.conversation_id = conversation_id or f"conv_{datetime.now().timestamp()}"
        
        # Store conversation start
        self.memory_system.store_memory(
            f"Started conversation {self.conversation_id}",
            {"conversation_id": self.conversation_id, "importance": 0.3},
            "episodic"
        )
    
    def process_message(self, user_message: str) -> str:
        """Process user message with memory integration"""
        # Store user message
        self.memory_system.store_memory(
            f"User: {user_message}",
            {"conversation_id": self.conversation_id, "importance": 0.6},
            "episodic"
        )
        
        # Retrieve relevant memories
        relevant_memories = self.memory_system.retrieve_memory(
            user_message, k=3, memory_types=["episodic", "semantic"]
        )
        
        # Create context from memories
        memory_context = "\n".join([
            f"Memory: {memory.content}" for memory in relevant_memories
        ])
        
        # Generate response with memory context
        prompt = f"""
        Previous relevant memories:
        {memory_context}
        
        Current user message: {user_message}
        
        Respond naturally, taking into account the conversation history and relevant memories.
        """
        
        response = self._generate_response(prompt)
        
        # Store agent response
        self.memory_system.store_memory(
            f"Agent: {response}",
            {"conversation_id": self.conversation_id, "importance": 0.5},
            "episodic"
        )
        
        # Periodic memory consolidation
        self.memory_system.consolidate_memories()
        
        return response
    
    def _generate_response(self, prompt: str) -> str:
        """Generate response using LLM"""
        # Mock implementation - replace with actual LLM call
        return f"Response based on: {prompt[:100]}..."
    
    def learn_from_feedback(self, feedback: str, importance: float = 0.8):
        """Learn from user feedback"""
        self.memory_system.store_memory(
            f"Feedback: {feedback}",
            {
                "conversation_id": self.conversation_id,
                "importance": importance,
                "type": "feedback"
            },
            "procedural"
        )
    
    def remember_fact(self, fact: str, category: str = "general"):
        """Store a fact in semantic memory"""
        self.memory_system.store_memory(
            fact,
            {
                "category": category,
                "importance": 0.9,
                "type": "fact"
            },
            "semantic"
        )
#+END_SRC

** Hour 2: Advanced Memory Patterns

#+BEGIN_SRC python
import redis
from typing import Union
import numpy as np
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer

class DistributedMemory:
    """Distributed memory system using Redis"""
    
    def __init__(self, redis_host: str = "localhost", redis_port: int = 6379):
        self.redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)
        self.memory_prefix = "agent_memory:"
        self.conversation_prefix = "conversation:"
    
    def store_conversation_memory(self, conversation_id: str, message: str, metadata: Dict[str, Any]):
        """Store conversation-specific memory"""
        key = f"{self.conversation_prefix}{conversation_id}"
        
        memory_entry = {
            "message": message,
            "timestamp": datetime.now().isoformat(),
            "metadata": json.dumps(metadata)
        }
        
        # Add to conversation list
        self.redis_client.lpush(key, json.dumps(memory_entry))
        
        # Keep only last 100 messages per conversation
        self.redis_client.ltrim(key, 0, 99)
        
        # Set expiration (30 days)
        self.redis_client.expire(key, 30 * 24 * 3600)
    
    def get_conversation_history(self, conversation_id: str, limit: int = 10) -> List[Dict]:
        """Get conversation history"""
        key = f"{self.conversation_prefix}{conversation_id}"
        
        messages = self.redis_client.lrange(key, 0, limit - 1)
        return [json.loads(msg) for msg in messages]
    
    def store_global_memory(self, memory_id: str, content: str, metadata: Dict[str, Any]):
        """Store global memory accessible across conversations"""
        key = f"{self.memory_prefix}{memory_id}"
        
        memory_data = {
            "content": content,
            "metadata": json.dumps(metadata),
            "created": datetime.now().isoformat(),
            "access_count": 0
        }
        
        self.redis_client.hset(key, mapping=memory_data)
    
    def get_global_memory(self, memory_id: str) -> Optional[Dict]:
        """Get global memory and increment access count"""
        key = f"{self.memory_prefix}{memory_id}"
        
        memory_data = self.redis_client.hgetall(key)
        if not memory_data:
            return None
        
        # Increment access count
        self.redis_client.hincrby(key, "access_count", 1)
        
        return {
            "content": memory_data["content"],
            "metadata": json.loads(memory_data["metadata"]),
            "created": memory_data["created"],
            "access_count": int(memory_data["access_count"])
        }
    
    def search_memories(self, pattern: str) -> List[str]:
        """Search for memory keys matching pattern"""
        return self.redis_client.keys(f"{self.memory_prefix}*{pattern}*")

class AdaptiveMemory:
    """Memory system that adapts based on usage patterns"""
    
    def __init__(self):
        self.memory_store = {}
        self.access_patterns = {}
        self.forgetting_curve = {}
        self.clustering_model = None
        self.vectorizer = TfidfVectorizer(max_features=100)
    
    def store_with_adaptation(self, content: str, metadata: Dict[str, Any]) -> str:
        """Store memory with adaptive importance scoring"""
        memory_id = hashlib.md5(f"{content}{datetime.now()}".encode()).hexdigest()[:16]
        
        # Calculate initial importance based on multiple factors
        importance = self._calculate_adaptive_importance(content, metadata)
        
        memory_entry = {
            "id": memory_id,
            "content": content,
            "metadata": metadata,
            "importance": importance,
            "created": datetime.now(),
            "last_accessed": datetime.now(),
            "access_count": 0,
            "decay_rate": self._calculate_decay_rate(metadata)
        }
        
        self.memory_store[memory_id] = memory_entry
        self.access_patterns[memory_id] = []
        
        return memory_id
    
    def retrieve_with_adaptation(self, query: str, k: int = 5) -> List[Dict]:
        """Retrieve memories with adaptive ranking"""
        current_time = datetime.now()
        
        # Update forgetting curves
        self._update_forgetting_curves(current_time)
        
        # Score all memories
        scored_memories = []
        
        for memory_id, memory in self.memory_store.items():
            # Base relevance score
            relevance = self._calculate_relevance(query, memory["content"])
            
            # Adaptive factors
            recency_score = self._calculate_recency_score(memory["last_accessed"], current_time)
            importance_score = memory["importance"]
            usage_pattern_score = self._calculate_usage_pattern_score(memory_id, current_time)
            forgetting_factor = self.forgetting_curve.get(memory_id, 1.0)
            
            # Combined score
            final_score = (
                relevance * 0.4 +
                importance_score * 0.25 +
                recency_score * 0.15 +
                usage_pattern_score * 0.1 +
                forgetting_factor * 0.1
            )
            
            scored_memories.append((final_score, memory))
        
        # Sort and select top k
        scored_memories.sort(key=lambda x: x[0], reverse=True)
        
        # Update access patterns for retrieved memories
        retrieved_memories = []
        for score, memory in scored_memories[:k]:
            memory_id = memory["id"]
            
            # Update access information
            self.memory_store[memory_id]["access_count"] += 1
            self.memory_store[memory_id]["last_accessed"] = current_time
            self.access_patterns[memory_id].append(current_time)
            
            # Update importance based on access
            self._update_importance(memory_id)
            
            retrieved_memories.append(memory)
        
        return retrieved_memories
    
    def _calculate_adaptive_importance(self, content: str, metadata: Dict[str, Any]) -> float:
        """Calculate importance using multiple signals"""
        base_importance = metadata.get("importance", 0.5)
        
        # Content-based factors
        content_length_factor = min(len(content) / 1000, 1.0)  # Longer content slightly more important
        keyword_density = self._calculate_keyword_density(content)
        
        # Metadata-based factors
        context_importance = metadata.get("context_importance", 0.5)
        user_specified_importance = metadata.get("user_importance", 0.5)
        
        # Combine factors
        adaptive_importance = (
            base_importance * 0.3 +
            content_length_factor * 0.1 +
            keyword_density * 0.2 +
            context_importance * 0.2 +
            user_specified_importance * 0.2
        )
        
        return min(max(adaptive_importance, 0.0), 1.0)
    
    def _calculate_decay_rate(self, metadata: Dict[str, Any]) -> float:
        """Calculate how quickly memory should decay"""
        memory_type = metadata.get("type", "general")
        
        decay_rates = {
            "fact": 0.01,        # Facts decay slowly
            "procedure": 0.02,   # Procedures decay slowly
            "episodic": 0.05,    # Episodes decay moderately
            "working": 0.1,      # Working memory decays quickly
            "temporary": 0.2     # Temporary info decays very quickly
        }
        
        return decay_rates.get(memory_type, 0.05)
    
    def _update_forgetting_curves(self, current_time: datetime):
        """Update forgetting curves for all memories"""
        for memory_id, memory in self.memory_store.items():
            last_accessed = memory["last_accessed"]
            decay_rate = memory["decay_rate"]
            
            # Calculate time since last access (in hours)
            time_diff = (current_time - last_accessed).total_seconds() / 3600
            
            # Exponential decay
            forgetting_factor = np.exp(-decay_rate * time_diff)
            self.forgetting_curve[memory_id] = forgetting_factor
    
    def _calculate_usage_pattern_score(self, memory_id: str, current_time: datetime) -> float:
        """Calculate score based on usage patterns"""
        access_times = self.access_patterns.get(memory_id, [])
        
        if len(access_times) < 2:
            return 0.5
        
        # Calculate access frequency
        time_span = (current_time - access_times[0]).total_seconds() / 3600  # in hours
        if time_span == 0:
            return 0.5
        
        frequency = len(access_times) / time_span
        
        # Calculate regularity (inverse of variance in access intervals)
        if len(access_times) > 2:
            intervals = [(access_times[i] - access_times[i-1]).total_seconds() 
                        for i in range(1, len(access_times))]
            regularity = 1.0 / (1.0 + np.var(intervals))
        else:
            regularity = 0.5
        
        return min(frequency * 0.7 + regularity * 0.3, 1.0)
    
    def _update_importance(self, memory_id: str):
        """Update memory importance based on access patterns"""
        memory = self.memory_store[memory_id]
        access_count = memory["access_count"]
        
        # Increase importance based on access frequency
        access_boost = min(access_count * 0.1, 0.3)
        memory["importance"] = min(memory["importance"] + access_boost, 1.0)
    
    def _calculate_relevance(self, query: str, content: str) -> float:
        """Calculate relevance score"""
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        
        if not query_words:
            return 0.0
        
        intersection = len(query_words.intersection(content_words))
        return intersection / len(query_words)
    
    def _calculate_recency_score(self, last_accessed: datetime, current_time: datetime) -> float:
        """Calculate recency score"""
        time_diff = (current_time - last_accessed).total_seconds() / 3600  # in hours
        return np.exp(-time_diff / 24)  # Decay over 24 hours
    
    def _calculate_keyword_density(self, content: str) -> float:
        """Calculate keyword density for importance scoring"""
        # Simple implementation - count important words
        important_words = {'important', 'critical', 'urgent', 'remember', 'note', 'key'}
        words = content.lower().split()
        
        if not words:
            return 0.0
        
        important_count = sum(1 for word in words if word in important_words)
        return min(important_count / len(words), 0.5)
    
    def cluster_memories(self) -> Dict[str, List[str]]:
        """Cluster memories by content similarity"""
        if len(self.memory_store) < 3:
            return {}
        
        # Prepare content for clustering
        contents = [memory["content"] for memory in self.memory_store.values()]
        memory_ids = list(self.memory_store.keys())
        
        # Vectorize content
        try:
            tfidf_matrix = self.vectorizer.fit_transform(contents)
            
            # Perform clustering
            n_clusters = min(5, len(contents) // 2)  # Dynamic cluster count
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            cluster_labels = kmeans.fit_predict(tfidf_matrix)
            
            # Group memories by cluster
            clusters = {}
            for i, label in enumerate(cluster_labels):
                if label not in clusters:
                    clusters[label] = []
                clusters[label].append(memory_ids[i])
            
            return clusters
            
        except Exception as e:
            print(f"Clustering failed: {e}")
            return {}

# Memory optimization utilities
class MemoryOptimizer:
    """Utilities for optimizing memory usage"""
    
    @staticmethod
    def compress_old_memories(memory_system: HybridMemorySystem, days_threshold: int = 30):
        """Compress old memories to save space"""
        cutoff_date = datetime.now() - timedelta(days=days_threshold)
        
        # This would implement memory compression logic
        # For example, summarizing old conversation threads
        pass
    
    @staticmethod
    def cleanup_unused_memories(memory_system: HybridMemorySystem, access_threshold: int = 1):
        """Remove memories that haven't been accessed much"""
        # Implementation would identify and remove low-value memories
        pass
    
    @staticmethod
    def merge_similar_memories(memory_system: HybridMemorySystem, similarity_threshold: float = 0.9):
        """Merge very similar memories to reduce redundancy"""
        # Implementation would identify and merge similar memories
        pass

# Usage example
def memory_management_example():
    """Example of comprehensive memory management"""
    
    # Create memory-aware agent
    memory_agent = MemoryAwareAgent(None)  # LLM client would go here
    
    # Start conversation
    memory_agent.start_conversation("user_123_session_1")
    
    # Process messages with memory
    response1 = memory_agent.process_message("Hi, I'm working on a Python project")
    print(f"Response 1: {response1}")
    
    response2 = memory_agent.process_message("Can you help me with error handling?")
    print(f"Response 2: {response2}")
    
    # Agent remembers context from previous messages
    response3 = memory_agent.process_message("What was I working on again?")
    print(f"Response 3: {response3}")
    
    # Store important facts
    memory_agent.remember_fact("User prefers Python for data science projects", "user_preferences")
    
    # Get memory statistics
    stats = memory_agent.memory_system.get_memory_stats()
    print(f"Memory stats: {stats}")
    
    # Test adaptive memory
    adaptive_memory = AdaptiveMemory()
    
    # Store some memories
    id1 = adaptive_memory.store_with_adaptation("Python error handling best practices", 
                                               {"importance": 0.8, "type": "procedure"})
    
    id2 = adaptive_memory.store_with_adaptation("Meeting at 3pm tomorrow", 
                                               {"importance": 0.6, "type": "temporary"})
    
    # Retrieve with adaptation
    results = adaptive_memory.retrieve_with_adaptation("Python error", k=2)
    print(f"Adaptive retrieval results: {len(results)} memories found")

if __name__ == "__main__":
    memory_management_example()
#+END_SRC

** 15-min Review Questions:
1. What are the different types of memory in AI agents and when to use each?
2. How does the forgetting curve affect memory retrieval in adaptive systems?
3. What are the trade-offs between different memory storage approaches?

* Session 9: Deployment & Production Systems (2 hours)
*Focus:* Taking agents from development to production

** Hour 1: Containerization & API Development

#+BEGIN_SRC python
# FastAPI deployment setup
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
import asyncio
import uvicorn
import os
from datetime import datetime
import logging
import redis
from contextlib import asynccontextmanager

# Request/Response models
class AgentRequest(BaseModel):
    message: str = Field(..., description="User message to process")
    conversation_id: Optional[str] = Field(None, description="Conversation identifier")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)
    agent_type: Optional[str] = Field("general", description="Type of agent to use")

class AgentResponse(BaseModel):
    response: str
    conversation_id: str
    timestamp: datetime
    metadata: Dict[str, Any] = Field(default_factory=dict)
    processing_time: float

class HealthResponse(BaseModel):
    status: str
    timestamp: datetime
    version: str
    components: Dict[str, str]

# Global state management
class AppState:
    def __init__(self):
        self.agents = {}
        self.redis_client = None
        self.is_healthy = True

app_state = AppState()

# Lifespan management
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await initialize_agents()
    yield
    # Shutdown
    await cleanup_agents()

# FastAPI app
app = FastAPI(
    title="Agentic AI API",
    description="Production API for AI agents",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Verify API token"""
    token = credentials.credentials
    # Implement actual token verification
    if token != os.getenv("API_TOKEN", "default-token"):
        raise HTTPException(status_code=401, detail="Invalid token")
    return token

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Agent management
async def initialize_agents():
    """Initialize all agents on startup"""
    try:
        # Initialize Redis connection
        app_state.redis_client = redis.Redis(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", 6379)),
            decode_responses=True
        )
        
        # Initialize different agent types
        from your_agent_module import MemoryAwareAgent, ResearchAgent, WritingAgent
        
        app_state.agents = {
            "general": MemoryAwareAgent(None),  # Initialize with actual LLM client
            "research": ResearchAgent("research_agent", None, None),
            "writing": WritingAgent("writing_agent", None, None)
        }
        
        logger.info("Agents initialized successfully")
        
    except Exception as e:
        logger.error(f"Failed to initialize agents: {e}")
        app_state.is_healthy = False

async def cleanup_agents():
    """Cleanup agents on shutdown"""
    logger.info("Cleaning up agents...")
    # Implement cleanup logic
    pass

# Rate limiting
class RateLimiter:
    def __init__(self, redis_client, max_requests: int = 100, window: int = 3600):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window = window
    
    async def is_allowed(self, client_id: str) -> bool:
        """Check if client is within rate limits"""
        key = f"rate_limit:{client_id}"
        current = await self.redis.get(key)
        
        if current is None:
            await self.redis.setex(key, self.window, 1)
            return True
        
        if int(current) >= self.max_requests:
            return False
        
        await self.redis.incr(key)
        return True

rate_limiter = RateLimiter(app_state.redis_client)

# API endpoints
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    components = {
        "agents": "healthy" if app_state.agents else "unhealthy",
        "redis": "healthy" if app_state.redis_client else "unhealthy",
        "overall": "healthy" if app_state.is_healthy else "unhealthy"
    }
    
    return HealthResponse(
        status="healthy" if app_state.is_healthy else "unhealthy",
        timestamp=datetime.now(),
        version="1.0.0",
        components=components
    )

@app.post("/agent/chat", response_model=AgentResponse)
async def chat_with_agent(
    request: AgentRequest,
    background_tasks: BackgroundTasks,
    token: str = Depends(verify_token)
):
    """Main chat endpoint"""
    start_time = datetime.now()
    
    try:
        # Rate limiting (simplified - would use proper client identification)
        client_id = "default"  # Extract from token or IP
        if not await rate_limiter.is_allowed(client_id):
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
        
        # Get appropriate agent
        agent_type = request.agent_type
        if agent_type not in app_state.agents:
            raise HTTPException(status_code=400, detail=f"Unknown agent type: {agent_type}")
        
        agent = app_state.agents[agent_type]
        
        # Process message
        if hasattr(agent, 'process_message'):
            response_text = agent.process_message(request.message)
        else:
            # Fallback for agents without process_message method
            response_text = f"Processed by {agent_type}: {request.message}"
        
        # Calculate processing time
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Log request (background task)
        background_tasks.add_task(log_request, request, response_text, processing_time)
        
        return AgentResponse(
            response=response_text,
            conversation_id=request.conversation_id or f"conv_{start_time.timestamp()}",
            timestamp=datetime.now(),
            metadata={"agent_type": agent_type},
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"Error processing chat request: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@app.post("/agent/batch")
async def batch_process(
    requests: List[AgentRequest],
    token: str = Depends(verify_token)
):
    """Batch processing endpoint"""
    if len(requests) > 10:  # Limit batch size
        raise HTTPException(status_code=400, detail="Batch size too large")
    
    results = []
    
    # Process requests concurrently
    async def process_single(req):
        return await chat_with_agent(req, BackgroundTasks(), token)
    
    tasks = [process_single(req) for req in requests]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return {"results": results}

@app.get("/agent/stats")
async def get_agent_stats(token: str = Depends(verify_token)):
    """Get agent statistics"""
    stats = {}
    
    for agent_type, agent in app_state.agents.items():
        if hasattr(agent, 'get_stats'):
            stats[agent_type] = agent.get_stats()
        else:
            stats[agent_type] = {"status": "active"}
    
    return stats

async def log_request(request: AgentRequest, response: str, processing_time: float):
    """Log request for monitoring"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "message_length": len(request.message),
        "response_length": len(response),
        "processing_time": processing_time,
        "agent_type": request.agent_type
    }
    
    logger.info(f"Request processed: {log_entry}")

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # Set to False in production
        workers=1      # Adjust based on your needs
    )
#+END_SRC

** Hour 2: Monitoring, Scaling & Production Best Practices

#+BEGIN_SRC python
# Monitoring and observability
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
import asyncio
from typing import Callable
import functools

# Prometheus metrics
REQUEST_COUNT = Counter('agent_requests_total', 'Total agent requests', ['agent_type', 'status'])
REQUEST_DURATION = Histogram('agent_request_duration_seconds', 'Request duration', ['agent_type'])
ACTIVE_CONNECTIONS = Gauge('agent_active_connections', 'Active connections')
MEMORY_USAGE = Gauge('agent_memory_usage_bytes', 'Memory usage', ['component'])

class MetricsCollector:
    """Collect and expose metrics"""
    
    def __init__(self):
        self.start_time = time.time()
    
    def record_request(self, agent_type: str, duration: float, status: str):
        """Record request metrics"""
        REQUEST_COUNT.labels(agent_type=agent_type, status=status).inc()
        REQUEST_DURATION.labels(agent_type=agent_type).observe(duration)
    
    def update_memory_usage(self, component: str, usage: int):
        """Update memory usage metrics"""
        MEMORY_USAGE.labels(component=component).set(usage)
    
    def get_uptime(self) -> float:
        """Get application uptime"""
        return time.time() - self.start_time

metrics = MetricsCollector()

# Metrics endpoint for Prometheus
@app.get("/metrics")
async def get_metrics():
    """Prometheus metrics endpoint"""
    return generate_latest()

# Monitoring middleware
def monitor_requests(func: Callable) -> Callable:
    """Decorator to monitor function execution"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        status = "success"
        
        try:
            result = await func(*args, **kwargs)
            return result
        except Exception as e:
            status = "error"
            raise
        finally:
            duration = time.time() - start_time
            agent_type = kwargs.get('agent_type', 'unknown')
            metrics.record_request(agent_type, duration, status)
    
    return wrapper

# Production configuration
class ProductionConfig:
    """Production configuration settings"""
    
    def __init__(self):
        self.redis_config = {
            "host": os.getenv("REDIS_HOST", "localhost"),
            "port": int(os.getenv("REDIS_PORT", 6379)),
            "password": os.getenv("REDIS_PASSWORD"),
            "ssl": os.getenv("REDIS_SSL", "false").lower() == "true"
        }
        
        self.database_config = {
            "url": os.getenv("DATABASE_URL"),
            "pool_size": int(os.getenv("DB_POOL_SIZE", 10)),
            "max_overflow": int(os.getenv("DB_MAX_OVERFLOW", 20))
        }
        
        self.llm_config = {
            "openai_api_key": os.getenv("OPENAI_API_KEY"),
            "anthropic_api_key": os.getenv("ANTHROPIC_API_KEY"),
            "rate_limit": int(os.getenv("LLM_RATE_LIMIT", 100)),
            "timeout": int(os.getenv("LLM_TIMEOUT", 30))
        }
        
        self.monitoring_config = {
            "log_level": os.getenv("LOG_LEVEL", "INFO"),
            "metrics_enabled": os.getenv("METRICS_ENABLED", "true").lower() == "true",
            "tracing_enabled": os.getenv("TRACING_ENABLED", "true").lower() == "true"
        }

# Error handling and retry logic
import tenacity
from tenacity import retry, stop_after_attempt, wait_exponential

class ProductionAgent:
    """Production-ready agent with error handling and monitoring"""
    
    def __init__(self, config: ProductionConfig):
        self.config = config
        self.llm_client = self._init_llm_client()
        self.memory_system = self._init_memory_system()
        self.circuit_breaker = CircuitBreaker()
        
    def _init_llm_client(self):
        """Initialize LLM client with production settings"""
        # Implementation would initialize actual LLM client
        pass
    
    def _init_memory_system(self):
        """Initialize production memory system"""
        # Implementation would initialize production memory
        pass
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=tenacity.retry_if_exception_type(Exception)
    )
    async def process_with_retry(self, message: str) -> str:
        """Process message with retry logic"""
        if not self.circuit_breaker.can_execute():
            raise Exception("Circuit breaker open")
        
        try:
            result = await self._process_message_internal(message)
            self.circuit_breaker.record_success()
            return result
            
        except Exception as e:
            self.circuit_breaker.record_failure()
            logger.error(f"Processing failed: {e}")
            raise
    
    async def _process_message_internal(self, message: str) -> str:
        """Internal message processing"""
        # Actual processing logic would go here
        await asyncio.sleep(0.1)  # Simulate processing
        return f"Processed: {message}"

class CircuitBreaker:
    """Circuit breaker pattern for fault tolerance"""
    
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
    
    def can_execute(self) -> bool:
        """Check if circuit breaker allows execution"""
        if self.state == "closed":
            return True
        
        if self.state == "open":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "half-open"
                return True
            return False
        
        if self.state == "half-open":
            return True
        
        return False
    
    def record_success(self):
        """Record successful execution"""
        self.failure_count = 0
        self.state = "closed"
    
    def record_failure(self):
        """Record failed execution"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = "open"

# Load balancer for multiple agent instances
class AgentLoadBalancer:
    """Load balancer for distributing requests across agent instances"""
    
    def __init__(self):
        self.agents = []
        self.current_index = 0
        self.health_check_interval = 30
        self.last_health_check = 0
    
    def add_agent(self, agent: ProductionAgent):
        """Add agent to load balancer"""
        self.agents.append({
            "agent": agent,
            "healthy": True,
            "request_count": 0,
            "error_count": 0
        })
    
    def get_next_agent(self) -> ProductionAgent:
        """Get next available agent using round-robin"""
        if not self.agents:
            raise Exception("No agents available")
        
        # Perform health checks if needed
        if time.time() - self.last_health_check > self.health_check_interval:
            asyncio.create_task(self._health_check_all())
        
        # Find healthy agent
        healthy_agents = [a for a in self.agents if a["healthy"]]
        
        if not healthy_agents:
            raise Exception("No healthy agents available")
        
        # Round-robin selection
        agent_info = healthy_agents[self.current_index % len(healthy_agents)]
        self.current_index += 1
        
        return agent_info["agent"]
    
    async def _health_check_all(self):
        """Perform health check on all agents"""
        self.last_health_check = time.time()
        
        for agent_info in self.agents:
            try:
                # Simple health check - try to process a test message
                await agent_info["agent"].process_with_retry("health_check")
                agent_info["healthy"] = True
            except Exception:
                agent_info["healthy"] = False

# Distributed deployment with Docker
class DockerDeployment:
    """Utilities for Docker deployment"""
    
    @staticmethod
    def create_dockerfile() -> str:
        """Generate production Dockerfile"""
        return """
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd --create-home --shell /bin/bash agent
RUN chown -R agent:agent /app
USER agent

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
"""
    
    @staticmethod
    def create_docker_compose() -> str:
        """Generate docker-compose for full stack"""
        return """
version: '3.8'

services:
  agent-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - DATABASE_URL=postgresql://user:pass@postgres:5432/agents
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - redis
      - postgres
    deploy:
      replicas: 3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=agents
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agent-api

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:
"""

# Kubernetes deployment
class KubernetesDeployment:
    """Utilities for Kubernetes deployment"""
    
    @staticmethod
    def create_deployment_yaml() -> str:
        """Generate Kubernetes deployment"""
        return """
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-api
  labels:
    app: agent-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent-api
  template:
    metadata:
      labels:
        app: agent-api
    spec:
      containers:
      - name: agent-api
        image: your-registry/agent-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: openai-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

apiVersion: v1
kind: Service
metadata:
  name: agent-api-service
spec:
  selector:
    app: agent-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: agent-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: agent-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
"""

# Monitoring dashboard configuration
class MonitoringDashboard:
    """Grafana dashboard configuration"""
    
    @staticmethod
    def create_dashboard_json() -> str:
        """Generate Grafana dashboard JSON"""
        return """
{
  "dashboard": {
    "title": "Agent API Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(agent_requests_total[5m])",
            "legendFormat": "{{agent_type}} - {{status}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(agent_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(agent_requests_total{status='error'}[5m]) / rate(agent_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "agent_memory_usage_bytes",
            "legendFormat": "{{component}}"
          }
        ]
      }
    ]
  }
}
"""

# Production deployment utilities
class ProductionUtils:
    """Utilities for production deployment and management"""
    
    @staticmethod
    def create_nginx_config() -> str:
        """Generate nginx configuration for load balancing"""
        return """
upstream agent_backend {
    least_conn;
    server agent-api-1:8000;
    server agent-api-2:8000;
    server agent-api-3:8000;
}

server {
    listen 80;
    server_name your-domain.com;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    
    location / {
        limit_req zone=api burst=20 nodelay;
        
        proxy_pass http://agent_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # Health checks
        proxy_next_upstream error timeout http_502 http_503 http_504;
    }
    
    location /health {
        proxy_pass http://agent_backend;
        access_log off;
    }
    
    location /metrics {
        proxy_pass http://agent_backend;
        allow 10.0.0.0/8;
        deny all;
    }
}
"""
    
    @staticmethod
    def create_systemd_service() -> str:
        """Generate systemd service file"""
        return """
[Unit]
Description=Agent API Service
After=network.target
Requires=network.target

[Service]
Type=exec
User=agent
Group=agent
WorkingDirectory=/opt/agent-api
Environment=PATH=/opt/agent-api/venv/bin
ExecStart=/opt/agent-api/venv/bin/uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
ExecReload=/bin/kill -HUP $MAINPID
KillMode=mixed
TimeoutStopSec=5
PrivateTmp=true
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
"""

# Example production setup
async def setup_production_environment():
    """Example of setting up production environment"""
    
    # Initialize configuration
    config = ProductionConfig()
    
    # Create load balancer
    load_balancer = AgentLoadBalancer()
    
    # Create multiple agent instances
    for i in range(3):
        agent = ProductionAgent(config)
        load_balancer.add_agent(agent)
    
    # Example request processing
    try:
        agent = load_balancer.get_next_agent()
        result = await agent.process_with_retry("Hello, production!")
        print(f"Result: {result}")
        
    except Exception as e:
        logger.error(f"Production processing failed: {e}")
    
    return load_balancer

if __name__ == "__main__":
    # Generate deployment files
    docker_deployment = DockerDeployment()
    k8s_deployment = KubernetesDeployment()
    
    print("Dockerfile:")
    print(docker_deployment.create_dockerfile())
    
    print("\nDocker Compose:")
    print(docker_deployment.create_docker_compose())
    
    print("\nKubernetes Deployment:")
    print(k8s_deployment.create_deployment_yaml())
#+END_SRC

** 15-min Review Questions:
1. What are the key differences between development and production agent deployment?
2. How do you implement proper monitoring and observability for agents?
3. What are the main scalability considerations for production agent systems?

* Session 10: Security, Evaluation & Advanced Patterns (2 hours)
*Focus:* Security best practices and agent evaluation

** Hour 1: Security & Safety

#+BEGIN_SRC python
import hashlib
import hmac
import jwt
from typing import Dict, List, Optional, Set
import re
from datetime import datetime, timedelta
import bleach
from cryptography.fernet import Fernet
import secrets
import logging

# Input validation and sanitization
class InputValidator:
    """Comprehensive input validation for agent systems"""
    
    def __init__(self):
        # Dangerous patterns to block
        self.dangerous_patterns = [
            r'<script[^>]*>.*?</script>',  # XSS
            r'javascript:',                # JavaScript URLs
            r'vbscript:',                 # VBScript URLs
            r'on\w+\s*=',                 # Event handlers
            r'eval\s*\(',                 # Eval functions
            r'exec\s*\(',                 # Exec functions
            r'import\s+os',               # OS imports
            r'__import__',                # Dynamic imports
            r'subprocess',                # Subprocess calls
            r'system\s*\(',               # System calls
        ]
        
        self.compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.dangerous_patterns]
        
        # Maximum lengths
        self.max_lengths = {
            'message': 10000,
            'prompt': 5000,
            'filename': 255,
            'metadata_value': 1000
        }
    
    def validate_user_input(self, input_text: str, input_type: str = 'message') -> Dict[str, any]:
        """Validate and sanitize user input"""
        result = {
            'is_valid': True,
            'sanitized_input': input_text,
            'warnings': [],
            'blocked_reason': None
        }
        
        # Check length
        max_length = self.max_lengths.get(input_type, 1000)
        if len(input_text) > max_length:
            result['is_valid'] = False
            result['blocked_reason'] = f'Input too long (max {max_length} characters)'
            return result
        
        # Check for dangerous patterns
        for pattern in self.compiled_patterns:
            if pattern.search(input_text):
                result['is_valid'] = False
                result['blocked_reason'] = f'Potentially dangerous content detected'
                return result
        
        # Sanitize HTML
        result['sanitized_input'] = bleach.clean(
            input_text,
            tags=['b', 'i', 'em', 'strong', 'p', 'br'],
            attributes={},
            strip=True
        )
        
        # Check for prompt injection attempts
        injection_warnings = self._check_prompt_injection(input_text)
        result['warnings'].extend(injection_warnings)
        
        return result
    
    def _check_prompt_injection(self, text: str) -> List[str]:
        """Check for potential prompt injection attempts"""
        warnings = []
        
        injection_indicators = [
            'ignore previous instructions',
            'forget everything',
            'new instructions:',
            'system:',
            'assistant:',
            'user:',
            'override',
            'jailbreak',
            'pretend you are',
            'act as if',
            'roleplaying'
        ]
        
        text_lower = text.lower()
        for indicator in injection_indicators:
            if indicator in text_lower:
                warnings.append(f'Potential prompt injection detected: {indicator}')
        
        return warnings

class SecureAgentWrapper:
    """Secure wrapper for AI agents with safety controls"""
    
    def __init__(self, base_agent, security_config: Dict):
        self.base_agent = base_agent
        self.validator = InputValidator()
        self.security_config = security_config
        
        # Rate limiting
        self.rate_limits = {}
        self.max_requests_per_hour = security_config.get('max_requests_per_hour', 100)
        
        # Content filtering
        self.blocked_topics = set(security_config.get('blocked_topics', []))
        self.sensitive_data_patterns = self._compile_sensitive_patterns()
        
        # Audit logging
        self.audit_logger = self._setup_audit_logging()
        
        # Response filtering
        self.response_filter = ResponseFilter()
    
    def _compile_sensitive_patterns(self) -> List[re.Pattern]:
        """Compile patterns for detecting sensitive data"""
        patterns = [
            r'\b\d{3}-\d{2}-\d{4}\b',          # SSN
            r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',  # Credit card
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # Email
            r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b',  # IP address
            r'\b[A-Z]{2}\d{6,8}\b',            # Passport
        ]
        
        return [re.compile(pattern) for pattern in patterns]
    
    def _setup_audit_logging(self):
        """Setup audit logging"""
        audit_logger = logging.getLogger('agent_audit')
        audit_logger.setLevel(logging.INFO)
        
        handler = logging.FileHandler('agent_audit.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        audit_logger.addHandler(handler)
        
        return audit_logger
    
    async def secure_process(self, user_input: str, user_id: str, metadata: Dict = None) -> Dict:
        """Process input with comprehensive security checks"""
        start_time = datetime.now()
        
        try:
            # Rate limiting check
            if not self._check_rate_limit(user_id):
                self.audit_logger.warning(f'Rate limit exceeded for user {user_id}')
                return {
                    'success': False,
                    'error': 'Rate limit exceeded',
                    'error_code': 'RATE_LIMIT'
                }
            
            # Input validation
            validation_result = self.validator.validate_user_input(user_input)
            
            if not validation_result['is_valid']:
                self.audit_logger.warning(
                    f'Invalid input from user {user_id}: {validation_result["blocked_reason"]}'
                )
                return {
                    'success': False,
                    'error': 'Invalid input',
                    'error_code': 'INVALID_INPUT'
                }
            
            # Check for sensitive data
            sensitive_data_found = self._check_sensitive_data(validation_result['sanitized_input'])
            if sensitive_data_found:
                self.audit_logger.warning(f'Sensitive data detected from user {user_id}')
                return {
                    'success': False,
                    'error': 'Sensitive data detected',
                    'error_code': 'SENSITIVE_DATA'
                }
            
            # Process with base agent
            response = await self.base_agent.process_message(validation_result['sanitized_input'])
            
            # Filter response
            filtered_response = self.response_filter.filter_response(response)
            
            # Audit log successful interaction
            self.audit_logger.info(
                f'Successful interaction - User: {user_id}, '
                f'Input length: {len(user_input)}, '
                f'Response length: {len(filtered_response)}, '
                f'Processing time: {(datetime.now() - start_time).total_seconds():.2f}s'
            )
            
            return {
                'success': True,
                'response': filtered_response,
                'warnings': validation_result['warnings']
            }
            
        except Exception as e:
            self.audit_logger.error(f'Error processing request from user {user_id}: {str(e)}')
            return {
                'success': False,
                'error': 'Internal processing error',
                'error_code': 'INTERNAL_ERROR'
            }
    
    def _check_rate_limit(self, user_id: str) -> bool:
        """Check if user is within rate limits"""
        now = datetime.now()
        hour_ago = now - timedelta(hours=1)
        
        if user_id not in self.rate_limits:
            self.rate_limits[user_id] = []
        
        # Remove old requests
        self.rate_limits[user_id] = [
            req_time for req_time in self.rate_limits[user_id] 
            if req_time > hour_ago
        ]
        
        # Check limit
        if len(self.rate_limits[user_id]) >= self.max_requests_per_hour:
            return False
        
        # Add current request
        self.rate_limits[user_id].append(now)
        return True
    
    def _check_sensitive_data(self, text: str) -> bool:
        """Check for sensitive data in input"""
        for pattern in self.sensitive_data_patterns:
            if pattern.search(text):
                return True
        return False

class ResponseFilter:
    """Filter agent responses for safety and compliance"""
    
    def __init__(self):
        self.harmful_content_patterns = [
            r'how to (make|build|create) (bomb|explosive|weapon)',
            r'suicide methods',
            r'self[- ]harm',
            r'illegal drug',
            r'hack(ing)? (into|someone)',
            r'pirated? (software|content|movies?)',
        ]
        
        self.compiled_harmful_patterns = [
            re.compile(pattern, re.IGNORECASE) 
            for pattern in self.harmful_content_patterns
        ]
        
        # Replacement text for filtered content
        self.replacement_text = "[Content filtered for safety]"
    
    def filter_response(self, response: str) -> str:
        """Filter potentially harmful content from responses"""
        filtered_response = response
        
        # Check for harmful patterns
        for pattern in self.compiled_harmful_patterns:
            if pattern.search(filtered_response):
                # Replace harmful content
                filtered_response = pattern.sub(self.replacement_text, filtered_response)
        
        # Remove any remaining sensitive information
        filtered_response = self._remove_sensitive_info(filtered_response)
        
        return filtered_response
    
    def _remove_sensitive_info(self, text: str) -> str:
        """Remove sensitive information from text"""
        # Remove potential API keys
        text = re.sub(r'sk-[a-zA-Z0-9]{32,}', '[API_KEY_REDACTED]', text)
        
        # Remove potential passwords in code examples
        text = re.sub(r'password\s*=\s*["\'][^"\']+["\']', 'password="[REDACTED]"', text, flags=re.IGNORECASE)
        
        return text

# Authentication and authorization
class AgentAuthManager:
    """Manage authentication and authorization for agent access"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.user_permissions = {}
        self.api_keys = {}
    
    def generate_api_key(self, user_id: str, permissions: List[str]) -> str:
        """Generate API key for user"""
        api_key = secrets.token_urlsafe(32)
        
        self.api_keys[api_key] = {
            'user_id': user_id,
            'permissions': set(permissions),
            'created_at': datetime.now(),
            'last_used': None,
            'usage_count': 0
        }
        
        return api_key
    
    def validate_api_key(self, api_key: str) -> Optional[Dict]:
        """Validate API key and return user info"""
        if api_key not in self.api_keys:
            return None
        
        key_info = self.api_keys[api_key]
        key_info['last_used'] = datetime.now()
        key_info['usage_count'] += 1
        
        return key_info
    
    def check_permission(self, api_key: str, required_permission: str) -> bool:
        """Check if API key has required permission"""
        key_info = self.validate_api_key(api_key)
        
        if not key_info:
            return False
        
        return required_permission in key_info['permissions']
    
    def generate_jwt_token(self, user_id: str, permissions: List[str], expires_in: int = 3600) -> str:
        """Generate JWT token"""
        payload = {
            'user_id': user_id,
            'permissions': permissions,
            'exp': datetime.utcnow() + timedelta(seconds=expires_in),
            'iat': datetime.utcnow()
        }
        
        return jwt.encode(payload, self.secret_key, algorithm='HS256')
    
    def validate_jwt_token(self, token: str) -> Optional[Dict]:
        """Validate JWT token"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            return payload
        except jwt.ExpiredSignatureError:
            return None
        except jwt.InvalidTokenError:
            return None

# Data encryption for sensitive information
class DataEncryption:
    """Handle encryption of sensitive data"""
    
    def __init__(self):
        self.key = Fernet.generate_key()
        self.cipher_suite = Fernet(self.key)
    
    def encrypt_data(self, data: str) -> str:
        """Encrypt sensitive data"""
        return self.cipher_suite.encrypt(data.encode()).decode()
    
    def decrypt_data(self, encrypted_data: str) -> str:
        """Decrypt sensitive data"""
        return self.cipher_suite.decrypt(encrypted_data.encode()).decode()
    
    def hash_data(self, data: str, salt: str = None) -> str:
        """Create hash of data for secure comparison"""
        if salt is None:
            salt = secrets.token_hex(16)
        
        return hashlib.pbkdf2_hmac('sha256', data.encode(), salt.encode(), 100000).hex()

# Security monitoring
class SecurityMonitor:
    """Monitor for security threats and anomalies"""
    
    def __init__(self):
        self.threat_patterns = {}
        self.user_behavior = {}
        self.alert_thresholds = {
            'failed_auth_attempts': 5,
            'suspicious_requests_per_hour': 50,
            'rate_limit_hits_per_hour': 10
        }
    
    def log_security_event(self, event_type: str, user_id: str, details: Dict):
        """Log security event for monitoring"""
        timestamp = datetime.now()
        
        if user_id not in self.user_behavior:
            self.user_behavior[user_id] = {
                'failed_auth': 0,
                'suspicious_requests': 0,
                'rate_limit_hits': 0,
                'last_reset': timestamp
            }
        
        user_stats = self.user_behavior[user_id]
        
        # Reset hourly counters if needed
        if (timestamp - user_stats['last_reset']).seconds > 3600:
            user_stats.update({
                'failed_auth': 0,
                'suspicious_requests': 0,
                'rate_limit_hits': 0,
                'last_reset': timestamp
            })
        
        # Update counters
        if event_type == 'failed_auth':
            user_stats['failed_auth'] += 1
        elif event_type == 'suspicious_request':
            user_stats['suspicious_requests'] += 1
        elif event_type == 'rate_limit_hit':
            user_stats['rate_limit_hits'] += 1
        
        # Check for alerts
        self._check_security_alerts(user_id, user_stats)
    
    def _check_security_alerts(self, user_id: str, user_stats: Dict):
        """Check if security alerts should be triggered"""
        alerts = []
        
        for metric, threshold in self.alert_thresholds.items():
            if user_stats.get(metric.replace('_per_hour', ''), 0) >= threshold:
                alerts.append(f'{metric} threshold exceeded for user {user_id}')
        
        if alerts:
            self._send_security_alert(user_id, alerts)
    
    def _send_security_alert(self, user_id: str, alerts: List[str]):
        """Send security alert (implement with your alerting system)"""
        alert_message = f"Security Alert for user {user_id}:\n" + "\n".join(alerts)
        logging.warning(alert_message)
        # Implement actual alerting logic (email, Slack, etc.)
#+END_SRC

** Hour 2: Agent Evaluation & Testing

#+BEGIN_SRC python
import json
import asyncio
from typing import Dict, List, Any, Tuple
import pandas as pd
import numpy as np
from datetime import datetime
import pytest
from unittest.mock import Mock, patch

# Agent evaluation framework
class AgentEvaluator:
    """Comprehensive evaluation framework for AI agents"""
    
    def __init__(self):
        self.test_cases = []
        self.evaluation_metrics = {}
        self.results_history = []
    
    def add_test_case(self, test_case: Dict):
        """Add a test case to the evaluation suite"""
        required_fields = ['input', 'expected_output', 'category', 'difficulty']
        
        if not all(field in test_case for field in required_fields):
            raise ValueError(f"Test case must contain: {required_fields}")
        
        test_case['id'] = len(self.test_cases)
        test_case['created_at'] = datetime.now()
        self.test_cases.append(test_case)
    
    async def evaluate_agent(self, agent, test_subset: str = None) -> Dict[str, Any]:
        """Evaluate agent performance across test cases"""
        test_cases = self._get_test_subset(test_subset) if test_subset else self.test_cases
        
        results = {
            'timestamp': datetime.now(),
            'total_tests': len(test_cases),
            'passed': 0,
            'failed': 0,
            'errors': 0,
            'test_results': [],
            'metrics': {},
            'performance_stats': {}
        }
        
        start_time = datetime.now()
        
        for test_case in test_cases:
            result = await self._evaluate_single_test(agent, test_case)
            results['test_results'].append(result)
            
            if result['status'] == 'passed':
                results['passed'] += 1
            elif result['status'] == 'failed':
                results['failed'] += 1
            else:
                results['errors'] += 1
        
        # Calculate metrics
        results['metrics'] = self._calculate_metrics(results['test_results'])
        results['performance_stats'] = {
            'total_time': (datetime.now() - start_time).total_seconds(),
            'avg_response_time': np.mean([r['response_time'] for r in results['test_results']]),
            'success_rate': results['passed'] / results['total_tests']
        }
        
        self.results_history.append(results)
        return results
    
    async def _evaluate_single_test(self, agent, test_case: Dict) -> Dict[str, Any]:
        """Evaluate a single test case"""
        start_time = datetime.now()
        
        try:
            # Get agent response
            if hasattr(agent, 'process_message'):
                response = await agent.process_message(test_case['input'])
            else:
                response = str(agent)  # Fallback for testing
            
            response_time = (datetime.now() - start_time).total_seconds()
            
            # Evaluate response
            evaluation_result = self._evaluate_response(
                response, 
                test_case['expected_output'], 
                test_case['category']
            )
            
            return {
                'test_id': test_case['id'],
                'input': test_case['input'],
                'expected': test_case['expected_output'],
                'actual': response,
                'status': 'passed' if evaluation_result['passed'] else 'failed',
                'score': evaluation_result['score'],
                'response_time': response_time,
                'category': test_case['category'],
                'difficulty': test_case['difficulty'],
                'details': evaluation_result['details']
            }
            
        except Exception as e:
            return {
                'test_id': test_case['id'],
                'input': test_case['input'],
                'status': 'error',
                'error': str(e),
                'response_time': (datetime.now() - start_time).total_seconds(),
                'category': test_case['category'],
                'difficulty': test_case['difficulty']
            }
    
    def _evaluate_response(self, actual: str, expected: str, category: str) -> Dict[str, Any]:
        """Evaluate the quality of an agent response"""
        
        if category == 'exact_match':
            passed = actual.strip().lower() == expected.strip().lower()
            score = 1.0 if passed else 0.0
            
        elif category == 'contains_keywords':
            expected_keywords = expected.lower().split()
            actual_lower = actual.lower()
            matched_keywords = sum(1 for keyword in expected_keywords if keyword in actual_lower)
            score = matched_keywords / len(expected_keywords)
            passed = score >= 0.8
            
        elif category == 'semantic_similarity':
            # Simplified semantic similarity (would use embeddings in practice)
            actual_words = set(actual.lower().split())
            expected_words = set(expected.lower().split())
            
            if not expected_words:
                score = 0.0
            else:
                intersection = actual_words.intersection(expected_words)
                union = actual_words.union(expected_words)
                score = len(intersection) / len(union) if union else 0.0
            
            passed = score >= 0.6
            
        elif category == 'code_execution':
            # Test if generated code executes without errors
            try:
                exec(actual)
                passed = True
                score = 1.0
            except Exception as e:
                passed = False
                score = 0.0
                
        else:
            # Default evaluation
            passed = len(actual.strip()) > 0
            score = 0.5 if passed else 0.0
        
        return {
            'passed': passed,
            'score': score,
            'details': {
                'evaluation_method': category,
                'actual_length': len(actual),
                'expected_length': len(expected)
            }
        }
    
    def _calculate_metrics(self, test_results: List[Dict]) -> Dict[str, float]:
        """Calculate evaluation metrics"""
        if not test_results:
            return {}
        
        scores = [r.get('score', 0) for r in test_results if 'score' in r]
        response_times = [r['response_time'] for r in test_results]
        
        # Group by category
        category_scores = {}
        for result in test_results:
            category = result.get('category', 'unknown')
            if category not in category_scores:
                category_scores[category] = []
            if 'score' in result:
                category_scores[category].append(result['score'])
        
        # Group by difficulty
        difficulty_scores = {}
        for result in test_results:
            difficulty = result.get('difficulty', 'unknown')
            if difficulty not in difficulty_scores:
                difficulty_scores[difficulty] = []
            if 'score' in result:
                difficulty_scores[difficulty].append(result['score'])
        
        metrics = {
            'overall_score': np.mean(scores) if scores else 0.0,
            'score_std': np.std(scores) if scores else 0.0,
            'avg_response_time': np.mean(response_times),
            'response_time_std': np.std(response_times),
            'min_score': np.min(scores) if scores else 0.0,
            'max_score': np.max(scores) if scores else 0.0
        }
        
        # Add category-specific metrics
        for category, cat_scores in category_scores.items():
            if cat_scores:
                metrics[f'{category}_score'] = np.mean(cat_scores)
        
        # Add difficulty-specific metrics
        for difficulty, diff_scores in difficulty_scores.items():
            if diff_scores:
                metrics[f'{difficulty}_difficulty_score'] = np.mean(diff_scores)
        
        return metrics
    
    def _get_test_subset(self, subset_name: str) -> List[Dict]:
        """Get a subset of test cases"""
        if subset_name == 'quick':
            return [tc for tc in self.test_cases if tc.get('difficulty') == 'easy'][:10]
        elif subset_name == 'comprehensive':
            return self.test_cases
        else:
            return [tc for tc in self.test_cases if tc.get('category') == subset_name]
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """Generate a human-readable evaluation report"""
        report = f"""
Agent Evaluation Report
======================
Date: {results['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}

Summary:
--------
Total Tests: {results['total_tests']}
Passed: {results['passed']} ({results['passed']/results['total_tests']*100:.1f}%)
Failed: {results['failed']} ({results['failed']/results['total_tests']*100:.1f}%)
Errors: {results['errors']} ({results['errors']/results['total_tests']*100:.1f}%)

Performance:
-----------
Overall Score: {results['metrics'].get('overall_score', 0):.3f}
Average Response Time: {results['performance_stats']['avg_response_time']:.2f}s
Success Rate: {results['performance_stats']['success_rate']*100:.1f}%

Category Breakdown:
------------------
"""
        
        # Add category-specific scores
        categories = set(r.get('category', 'unknown') for r in results['test_results'])
        for category in categories:
            if f'{category}_score' in results['metrics']:
                score = results['metrics'][f'{category}_score']
                report += f"{category}: {score:.3f}\n"
        
        return report

# A/B testing framework for agents
class AgentABTester:
    """A/B testing framework for comparing agent versions"""
    
    def __init__(self):
        self.experiments = {}
        self.results = {}
    
    def create_experiment(self, experiment_id: str, agent_a, agent_b, test_cases: List[Dict]):
        """Create an A/B test experiment"""
        self.experiments[experiment_id] = {
            'agent_a': agent_a,
            'agent_b': agent_b,
            'test_cases': test_cases,
            'created_at': datetime.now()
        }
    
    async def run_experiment(self, experiment_id: str) -> Dict[str, Any]:
        """Run A/B test experiment"""
        if experiment_id not in self.experiments:
            raise ValueError(f"Experiment {experiment_id} not found")
        
        experiment = self.experiments[experiment_id]
        evaluator = AgentEvaluator()
        
        # Add test cases to evaluator
        for test_case in experiment['test_cases']:
            evaluator.add_test_case(test_case)
        
        # Evaluate both agents
        results_a = await evaluator.evaluate_agent(experiment['agent_a'])
        results_b = await evaluator.evaluate_agent(experiment['agent_b'])
        
        # Statistical comparison
        comparison = self._compare_results(results_a, results_b)
        
        experiment_result = {
            'experiment_id': experiment_id,
            'timestamp': datetime.now(),
            'agent_a_results': results_a,
            'agent_b_results': results_b,
            'comparison': comparison
        }
        
        self.results[experiment_id] = experiment_result
        return experiment_result
    
    def _compare_results(self, results_a: Dict, results_b: Dict) -> Dict[str, Any]:
        """Compare results between two agents"""
        comparison = {
            'winner': None,
            'confidence': 0.0,
            'metrics_comparison': {},
            'statistical_significance': False
        }
        
        # Compare key metrics
        metrics_to_compare = ['overall_score', 'avg_response_time', 'success_rate']
        
        for metric in metrics_to_compare:
            if metric in results_a['metrics'] and metric in results_b['metrics']:
                val_a = results_a['metrics'][metric]
                val_b = results_b['metrics'][metric]
                
                if metric == 'avg_response_time':
                    # Lower is better for response time
                    better = 'A' if val_a < val_b else 'B'
                    improvement = abs(val_a - val_b) / max(val_a, val_b) * 100
                else:
                    # Higher is better for other metrics
                    better = 'A' if val_a > val_b else 'B'
                    improvement = abs(val_a - val_b) / max(val_a, val_b) * 100
                
                comparison['metrics_comparison'][metric] = {
                    'agent_a': val_a,
                    'agent_b': val_b,
                    'better': better,
                    'improvement_percent': improvement
                }
        
        # Simple winner determination (would use proper statistical tests in practice)
        a_wins = sum(1 for comp in comparison['metrics_comparison'].values() if comp['better'] == 'A')
        b_wins = sum(1 for comp in comparison['metrics_comparison'].values() if comp['better'] == 'B')
        
        if a_wins > b_wins:
            comparison['winner'] = 'A'
            comparison['confidence'] = a_wins / (a_wins + b_wins)
        elif b_wins > a_wins:
            comparison['winner'] = 'B'
            comparison['confidence'] = b_wins / (a_wins + b_wins)
        else:
            comparison['winner'] = 'tie'
            comparison['confidence'] = 0.5
        
        return comparison

# Load testing for agents
class AgentLoadTester:
    """Load testing framework for agent performance under stress"""
    
    def __init__(self):
        self.results = []
    
    async def run_load_test(self, agent, test_config: Dict) -> Dict[str, Any]:
        """Run load test with specified configuration"""
        config = {
            'concurrent_users': test_config.get('concurrent_users', 10),
            'requests_per_user': test_config.get('requests_per_user', 10),
            'ramp_up_time': test_config.get('ramp_up_time', 30),
            'test_duration': test_config.get('test_duration', 300),
            'test_message': test_config.get('test_message', 'Hello, this is a load test message.')
        }
        
        results = {
            'config': config,
            'start_time': datetime.now(),
            'responses': [],
            'errors': [],
            'metrics': {}
        }
        
        # Create semaphore to limit concurrent requests
        semaphore = asyncio.Semaphore(config['concurrent_users'])
        
        async def single_user_test(user_id: int):
            """Simulate a single user's requests"""
            user_responses = []
            
            for request_num in range(config['requests_per_user']):
                async with semaphore:
                    start_time = datetime.now()
                    
                    try:
                        if hasattr(agent, 'process_message'):
                            response = await agent.process_message(config['test_message'])
                        else:
                            response = f"Mock response for user {user_id} request {request_num}"
                        
                        response_time = (datetime.now() - start_time).total_seconds()
                        
                        user_responses.append({
                            'user_id': user_id,
                            'request_num': request_num,
                            'response_time': response_time,
                            'success': True,
                            'response_length': len(str(response))
                        })
                        
                    except Exception as e:
                        response_time = (datetime.now() - start_time).total_seconds()
                        results['errors'].append({
                            'user_id': user_id,
                            'request_num': request_num,
                            'error': str(e),
                            'response_time': response_time
                        })
            
            return user_responses
        
        # Run concurrent user simulations
        tasks = [single_user_test(i) for i in range(config['concurrent_users'])]
        user_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Flatten results
        for user_result in user_results:
            if isinstance(user_result, list):
                results['responses'].extend(user_result)
        
        # Calculate metrics
        results['end_time'] = datetime.now()
        results['metrics'] = self._calculate_load_test_metrics(results)
        
        self.results.append(results)
        return results
    
    def _calculate_load_test_metrics(self, results: Dict) -> Dict[str, float]:
        """Calculate load test metrics"""
        responses = results['responses']
        
        if not responses:
            return {'error': 'No successful responses'}
        
        response_times = [r['response_time'] for r in responses]
        total_time = (results['end_time'] - results['start_time']).total_seconds()
        
        metrics = {
            'total_requests': len(responses),
            'total_errors': len(results['errors']),
            'error_rate': len(results['errors']) / (len(responses) + len(results['errors'])),
            'avg_response_time': np.mean(response_times),
            'median_response_time': np.median(response_times),
            'p95_response_time': np.percentile(response_times, 95),
            'p99_response_time': np.percentile(response_times, 99),
            'min_response_time': np.min(response_times),
            'max_response_time': np.max(response_times),
            'requests_per_second': len(responses) / total_time,
            'total_test_duration': total_time
        }
        
        return metrics

# Automated testing suite
class AgentTestSuite:
    """Comprehensive automated testing suite for agents"""
    
    def __init__(self):
        self.unit_tests = []
        self.integration_tests = []
        self.performance_tests = []
    
    def add_unit_test(self, test_func):
        """Add unit test function"""
        self.unit_tests.append(test_func)
    
    def add_integration_test(self, test_func):
        """Add integration test function"""
        self.integration_tests.append(test_func)
    
    def add_performance_test(self, test_func):
        """Add performance test function"""
        self.performance_tests.append(test_func)
    
    async def run_all_tests(self, agent) -> Dict[str, Any]:
        """Run all tests in the suite"""
        results = {
            'timestamp': datetime.now(),
            'unit_tests': await self._run_test_group(self.unit_tests, agent, 'unit'),
            'integration_tests': await self._run_test_group(self.integration_tests, agent, 'integration'),
            'performance_tests': await self._run_test_group(self.performance_tests, agent, 'performance'),
            'summary': {}
        }
        
        # Calculate summary
        all_results = results['unit_tests'] + results['integration_tests'] + results['performance_tests']
        results['summary'] = {
            'total_tests': len(all_results),
            'passed': sum(1 for r in all_results if r['status'] == 'passed'),
            'failed': sum(1 for r in all_results if r['status'] == 'failed'),
            'errors': sum(1 for r in all_results if r['status'] == 'error')
        }
        
        return results
    
    async def _run_test_group(self, tests: List, agent, test_type: str) -> List[Dict]:
        """Run a group of tests"""
        results = []
        
        for i, test_func in enumerate(tests):
            test_name = getattr(test_func, '__name__', f'{test_type}_test_{i}')
            start_time = datetime.now()
            
            try:
                if asyncio.iscoroutinefunction(test_func):
                    test_result = await test_func(agent)
                else:
                    test_result = test_func(agent)
                
                results.append({
                    'name': test_name,
                    'type': test_type,
                    'status': 'passed' if test_result else 'failed',
                    'duration': (datetime.now() - start_time).total_seconds(),
                    'result': test_result
                })
                
            except Exception as e:
                results.append({
                    'name': test_name,
                    'type': test_type,
                    'status': 'error',
                    'duration': (datetime.now() - start_time).total_seconds(),
                    'error': str(e)
                })
        
        return results

# Example test implementations
def test_basic_response(agent):
    """Test basic agent response functionality"""
    # This would be a real test implementation
    return True

async def test_async_processing(agent):
    """Test asynchronous processing"""
    if hasattr(agent, 'process_message'):
        result = await agent.process_message("Test message")
        return len(str(result)) > 0
    return True

def test_memory_persistence(agent):
    """Test memory persistence across interactions"""
    # This would test actual memory functionality
    return True

# Usage example
async def run_comprehensive_evaluation():
    """Example of running comprehensive agent evaluation"""
    
    # Create mock agent for testing
    class MockAgent:
        async def process_message(self, message: str) -> str:
            await asyncio.sleep(0.1)  # Simulate processing time
            return f"Processed: {message}"
    
    agent = MockAgent()
    
    # 1. Basic evaluation
    evaluator = AgentEvaluator()
    
    # Add test cases
    evaluator.add_test_case({
        'input': 'Hello',
        'expected_output': 'processed: hello',
        'category': 'contains_keywords',
        'difficulty': 'easy'
    })
    
    evaluator.add_test_case({
        'input': 'What is 2+2?',
        'expected_output': '4',
        'category': 'exact_match',
        'difficulty': 'medium'
    })
    
    # Run evaluation
    results = await evaluator.evaluate_agent(agent)
    print("Evaluation Results:")
    print(evaluator.generate_report(results))
    
    # 2. Load testing
    load_tester = AgentLoadTester()
    load_config = {
        'concurrent_users': 5,
        'requests_per_user': 10,
        'test_message': 'Load test message'
    }
    
    load_results = await load_tester.run_load_test(agent, load_config)
    print(f"\nLoad Test Results:")
    print(f"Requests per second: {load_results['metrics']['requests_per_second']:.2f}")
    print(f"Average response time: {load_results['metrics']['avg_response_time']:.3f}s")
    print(f"Error rate: {load_results['metrics']['error_rate']*100:.1f}%")
    
    # 3. Automated test suite
    test_suite = AgentTestSuite()
    test_suite.add_unit_test(test_basic_response)
    test_suite.add_integration_test(test_async_processing)
    test_suite.add_performance_test(test_memory_persistence)
    
    suite_results = await test_suite.run_all_tests(agent)
    print(f"\nTest Suite Results:")
    print(f"Total tests: {suite_results['summary']['total_tests']}")
    print(f"Passed: {suite_results['summary']['passed']}")
    print(f"Failed: {suite_results['summary']['failed']}")

if __name__ == "__main__":
    asyncio.run(run_comprehensive_evaluation())
#+END_SRC

** 15-min Review Questions:
1. What are the key security considerations when deploying AI agents?
2. How do you design comprehensive evaluation metrics for agent performance?
3. What are the differences between unit testing, integration testing, and load testing for agents?

** Summary
This 20-hour roadmap covers the essential skills for building production-ready AI agents:
- *Sessions 1-2:* Foundation skills (Python, APIs, LLMs, prompting)
- *Sessions 3-4:* Core agent architecture and tool integration
- *Sessions 5-7:* Advanced frameworks and multi-agent systems
- *Sessions 8-9:* Production deployment and memory management
- *Session 10:* Security, evaluation, and best practices

Each session builds upon the previous ones, providing hands-on experience with real-world agent development challenges.

